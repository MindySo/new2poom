"""
Gradio Web UI for SigLIP Person Finder
Interactive interface for text-based person search

Usage:
    python app_gradio.py
"""

# Fix for Windows asyncio issue
import sys
import asyncio
if sys.platform == 'win32':
    asyncio.set_event_loop_policy(asyncio.WindowsSelectorEventLoopPolicy())

import gradio as gr
import numpy as np
from PIL import Image
import logging
from typing import List, Tuple, Optional
import cv2

from model import SigLIPPersonFinder
from video_pipeline import PersonSearchPipeline

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# Global model instance (lazy loading)
finder = None
pipeline = None


def get_models():
    """Lazy load models"""
    global finder, pipeline
    if finder is None:
        logger.info("Loading SigLIP model...")
        finder = SigLIPPersonFinder()
        pipeline = PersonSearchPipeline(siglip_model=finder)
        logger.info("Models loaded!")
    return finder, pipeline


def search_images(
    text_query: str,
    images: List[Image.Image],
    threshold: float,
    detect_persons: bool
) -> Tuple[List[Tuple[Image.Image, str]], str]:
    """
    Search for person in images using text query.

    Args:
        text_query: Text description of person
        images: List of PIL Images
        threshold: Similarity threshold
        detect_persons: Whether to detect persons first

    Returns:
        Gallery of results and status message
    """
    if not text_query or not text_query.strip():
        return [], "âš ï¸ í…ìŠ¤íŠ¸ ì¿¼ë¦¬ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”!"

    if not images:
        return [], "âš ï¸ ì´ë¯¸ì§€ë¥¼ ì—…ë¡œë“œí•´ì£¼ì„¸ìš”!"

    try:
        model, pipe = get_models()

        if detect_persons:
            # Use pipeline to detect persons first
            logger.info("Detecting persons in images...")
            all_crops = []
            crop_info = []

            for img_idx, img in enumerate(images):
                # Convert PIL to cv2
                img_cv = cv2.cvtColor(np.array(img), cv2.COLOR_RGB2BGR)

                # Detect persons
                bboxes = pipe.detect_persons(img_cv)

                # Crop each person
                for bbox_idx, bbox in enumerate(bboxes):
                    crop = pipe.crop_person(img_cv, bbox)
                    if crop is not None:
                        all_crops.append(crop)
                        crop_info.append({
                            'image_idx': img_idx,
                            'bbox_idx': bbox_idx,
                            'bbox': bbox
                        })

            if not all_crops:
                return [], "âš ï¸ ì´ë¯¸ì§€ì—ì„œ ì‚¬ëŒì„ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤!"

            # Search in cropped persons
            results = model.search(
                text_query=text_query,
                images=all_crops,
                threshold=threshold
            )

            # Format results
            gallery = []
            for result in results:
                crop = result['image']
                sim = result['similarity']
                idx = result['index']
                info = crop_info[idx]

                caption = f"ìœ ì‚¬ë„: {sim:.3f}\nì´ë¯¸ì§€ #{info['image_idx']+1}, ì‚¬ëŒ #{info['bbox_idx']+1}"
                gallery.append((crop, caption))

        else:
            # Direct search without detection
            results = model.search(
                text_query=text_query,
                images=images,
                threshold=threshold
            )

            # Format results
            gallery = []
            for result in results:
                img = result['image']
                sim = result['similarity']
                idx = result['index']

                caption = f"ìœ ì‚¬ë„: {sim:.3f}\nì´ë¯¸ì§€ #{idx+1}"
                gallery.append((img, caption))

        if not gallery:
            status = f"âŒ ë§¤ì¹­ë˜ëŠ” ì‚¬ëŒì„ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤ (ì„ê³„ê°’: {threshold:.2f})"
        else:
            status = f"âœ… {len(gallery)}ëª…ì˜ ë§¤ì¹­ì„ ì°¾ì•˜ìŠµë‹ˆë‹¤! (ì„ê³„ê°’: {threshold:.2f})"

        return gallery, status

    except Exception as e:
        logger.error(f"Search error: {e}")
        return [], f"âŒ ì˜¤ë¥˜ ë°œìƒ: {str(e)}"


def search_video(
    text_query: str,
    video_file: str,
    threshold: float,
    frame_skip: int,
    max_results: int
) -> Tuple[List[Tuple[Image.Image, str]], str]:
    """
    Search for person in video using text query.

    Args:
        text_query: Text description
        video_file: Path to video file
        threshold: Similarity threshold
        frame_skip: Process every N frames
        max_results: Maximum results to show

    Returns:
        Gallery of results and status message
    """
    if not text_query or not text_query.strip():
        return [], "âš ï¸ í…ìŠ¤íŠ¸ ì¿¼ë¦¬ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”!"

    if not video_file:
        return [], "âš ï¸ ë¹„ë””ì˜¤ë¥¼ ì—…ë¡œë“œí•´ì£¼ì„¸ìš”!"

    try:
        model, pipe = get_models()

        # Update pipeline settings
        pipe.similarity_threshold = threshold
        pipe.frame_skip = frame_skip

        # Search in video
        logger.info(f"Searching in video: {video_file}")
        results = pipe.search_in_video(
            video_path=video_file,
            text_query=text_query,
            max_results=max_results,
            save_results=False  # Don't save to disk
        )

        if not results:
            return [], f"âŒ ë¹„ë””ì˜¤ì—ì„œ ë§¤ì¹­ì„ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤ (ì„ê³„ê°’: {threshold:.2f})"

        # Format results
        gallery = []
        for result in results:
            crop = result['person_crop']
            sim = result['similarity']
            timestamp = result['timestamp']
            frame = result['frame_idx']

            caption = f"ìœ ì‚¬ë„: {sim:.3f}\nì‹œê°„: {timestamp:.2f}ì´ˆ (í”„ë ˆì„ {frame})"
            gallery.append((crop, caption))

        status = f"âœ… {len(results)}ê°œì˜ ë§¤ì¹­ì„ ì°¾ì•˜ìŠµë‹ˆë‹¤! (ì„ê³„ê°’: {threshold:.2f})"
        return gallery, status

    except Exception as e:
        logger.error(f"Video search error: {e}")
        return [], f"âŒ ì˜¤ë¥˜ ë°œìƒ: {str(e)}"


# Example queries
example_queries = [
    ["ë‚¨ì, íŒŒë€ìƒ‰ ìƒì˜, ê²€ì€ìƒ‰ ë°”ì§€"],
    ["A man wearing a white t-shirt and black pants"],
    ["ì—¬ì, ë¹¨ê°„ìƒ‰ ì¬í‚·, ê¸´ ë¨¸ë¦¬"],
    ["A person with a blue backpack"],
]


# Build Gradio Interface
with gr.Blocks(title="SigLIP Person Finder", theme=gr.themes.Soft()) as demo:
    gr.Markdown("""
    # ğŸ” SigLIP Person Finder

    í…ìŠ¤íŠ¸ ê¸°ë°˜ ì¸ë¬¼ ê²€ìƒ‰ ì‹œìŠ¤í…œ - ìì—°ì–´ ì„¤ëª…ë§Œìœ¼ë¡œ ì‚¬ì§„ì´ë‚˜ ì˜ìƒì—ì„œ ì‚¬ëŒì„ ì°¾ì•„ëƒ…ë‹ˆë‹¤!

    **ì‚¬ìš©ë²•:**
    1. í…ìŠ¤íŠ¸ë¡œ ì°¾ê³  ì‹¶ì€ ì‚¬ëŒì˜ ì™¸ëª¨ë¥¼ ì„¤ëª…í•˜ì„¸ìš” (ì˜ˆ: "íŒŒë€ ìƒì˜ë¥¼ ì…ì€ ë‚¨ì")
    2. ì´ë¯¸ì§€ ë˜ëŠ” ë¹„ë””ì˜¤ë¥¼ ì—…ë¡œë“œí•˜ì„¸ìš”
    3. ì„ê³„ê°’ì„ ì¡°ì •í•˜ì„¸ìš” (ë‚®ì„ìˆ˜ë¡ ë” ë§ì€ ê²°ê³¼, ë†’ì„ìˆ˜ë¡ ë” ì •í™•í•œ ê²°ê³¼)
    4. ê²€ìƒ‰ ë²„íŠ¼ì„ í´ë¦­í•˜ì„¸ìš”!
    """)

    with gr.Tab("ğŸ“¸ ì´ë¯¸ì§€ ê²€ìƒ‰"):
        with gr.Row():
            with gr.Column(scale=1):
                text_input = gr.Textbox(
                    label="ì¸ìƒì°©ì˜ ì„¤ëª…",
                    placeholder="ì˜ˆ: íŒŒë€ìƒ‰ ìƒì˜ë¥¼ ì…ì€ ë‚¨ì, ê²€ì€ìƒ‰ ë°”ì§€",
                    lines=3
                )

                gr.Examples(
                    examples=example_queries,
                    inputs=text_input,
                    label="ì˜ˆì‹œ ì¿¼ë¦¬"
                )

                threshold_slider = gr.Slider(
                    minimum=0.0,
                    maximum=1.0,
                    value=0.30,
                    step=0.05,
                    label="ìœ ì‚¬ë„ ì„ê³„ê°’",
                    info="ë‚®ìŒ = ë” ë§ì€ ê²°ê³¼, ë†’ìŒ = ë” ì •í™•í•œ ê²°ê³¼"
                )

                detect_checkbox = gr.Checkbox(
                    label="ì‚¬ëŒ ìë™ ê²€ì¶œ (YOLO)",
                    value=True,
                    info="ì²´í¬ ì‹œ ì´ë¯¸ì§€ì—ì„œ ì‚¬ëŒì„ ë¨¼ì € ì°¾ì•„ë‚¸ í›„ ê²€ìƒ‰"
                )

                search_btn = gr.Button("ğŸ” ê²€ìƒ‰", variant="primary", size="lg")

                status_text = gr.Textbox(
                    label="ìƒíƒœ",
                    interactive=False,
                    lines=2
                )

            with gr.Column(scale=2):
                image_input = gr.Gallery(
                    label="ì´ë¯¸ì§€ ì—…ë¡œë“œ (ì—¬ëŸ¬ ì¥ ê°€ëŠ¥)",
                    type="pil",
                    columns=3,
                    height=300
                )

                result_gallery = gr.Gallery(
                    label="ê²€ìƒ‰ ê²°ê³¼",
                    columns=4,
                    height=400,
                    object_fit="contain"
                )

        search_btn.click(
            fn=search_images,
            inputs=[text_input, image_input, threshold_slider, detect_checkbox],
            outputs=[result_gallery, status_text]
        )

    with gr.Tab("ğŸ¥ ë¹„ë””ì˜¤ ê²€ìƒ‰"):
        with gr.Row():
            with gr.Column(scale=1):
                video_text_input = gr.Textbox(
                    label="ì¸ìƒì°©ì˜ ì„¤ëª…",
                    placeholder="ì˜ˆ: í°ìƒ‰ ì…”ì¸ ë¥¼ ì…ì€ ë‚¨ì",
                    lines=3
                )

                video_threshold = gr.Slider(
                    minimum=0.0,
                    maximum=1.0,
                    value=0.30,
                    step=0.05,
                    label="ìœ ì‚¬ë„ ì„ê³„ê°’"
                )

                frame_skip = gr.Slider(
                    minimum=1,
                    maximum=30,
                    value=5,
                    step=1,
                    label="í”„ë ˆì„ ìŠ¤í‚µ",
                    info="N í”„ë ˆì„ë§ˆë‹¤ ì²˜ë¦¬ (ë†’ì„ìˆ˜ë¡ ë¹ ë¦„)"
                )

                max_results = gr.Slider(
                    minimum=1,
                    maximum=50,
                    value=10,
                    step=1,
                    label="ìµœëŒ€ ê²°ê³¼ ìˆ˜"
                )

                video_search_btn = gr.Button("ğŸ” ë¹„ë””ì˜¤ ê²€ìƒ‰", variant="primary", size="lg")

                video_status = gr.Textbox(
                    label="ìƒíƒœ",
                    interactive=False,
                    lines=2
                )

            with gr.Column(scale=2):
                video_input = gr.Video(
                    label="ë¹„ë””ì˜¤ ì—…ë¡œë“œ"
                )

                video_result_gallery = gr.Gallery(
                    label="ê²€ìƒ‰ ê²°ê³¼",
                    columns=4,
                    height=400,
                    object_fit="contain"
                )

        video_search_btn.click(
            fn=search_video,
            inputs=[video_text_input, video_input, video_threshold, frame_skip, max_results],
            outputs=[video_result_gallery, video_status]
        )

    with gr.Tab("â„¹ï¸ ì‚¬ìš© ê°€ì´ë“œ"):
        gr.Markdown("""
        ## ğŸ“– ì‚¬ìš© ê°€ì´ë“œ

        ### ì¢‹ì€ í…ìŠ¤íŠ¸ ì¿¼ë¦¬ ì‘ì„±ë²•

        âœ… **ì¢‹ì€ ì˜ˆì‹œ:**
        - "ë‚¨ì, 30ëŒ€, í°ìƒ‰ í´ë¡œ ì…”ì¸ , ê²€ì€ìƒ‰ ë°”ì§€, í°ìƒ‰ ìš´ë™í™”"
        - "íŒŒë€ìƒ‰ ë°ë‹˜ ì¬í‚·ì„ ì…ì€ ì—¬ì, ê¸´ ë¨¸ë¦¬, ê²€ì€ìƒ‰ ê°€ë°©"
        - "A man wearing a white polo shirt and black pants with white sneakers"

        âŒ **ë‚˜ìœ ì˜ˆì‹œ:**
        - "í° ì˜·" (ë„ˆë¬´ ì§§ìŒ)
        - "ì‚¬ëŒ" (íŠ¹ì§• ì—†ìŒ)
        - "white" (ë„ˆë¬´ ëª¨í˜¸í•¨)

        ### ì„ê³„ê°’ ì„¤ì • ê°€ì´ë“œ

        | ì‚¬ìš© ì‚¬ë¡€ | ê¶Œì¥ ì„ê³„ê°’ | ì„¤ëª… |
        |---------|------------|------|
        | ì‹¤ì¢…ì ì°¾ê¸° | 0.25-0.30 | ë†’ì€ ì¬í˜„ìœ¨, ëª¨ë“  ê°€ëŠ¥ì„± í™•ì¸ |
        | CCTV ê°ì‹œ | 0.30-0.35 | ê· í˜•ì¡íŒ ì„¤ì • |
        | ì •ë°€ ê²€ìƒ‰ | 0.40-0.45 | ë†’ì€ ì •ë°€ë„ í•„ìš” |

        ### ì„±ëŠ¥ íŒ

        - **í”„ë ˆì„ ìŠ¤í‚µ**: ë¹„ë””ì˜¤ê°€ ê¸¸ ê²½ìš° 5-10 í”„ë ˆì„ë§ˆë‹¤ ì²˜ë¦¬í•˜ë©´ ë¹ ë¦…ë‹ˆë‹¤
        - **ì‚¬ëŒ ê²€ì¶œ**: ë°°ê²½ì´ ë§ì€ ì´ë¯¸ì§€ëŠ” "ì‚¬ëŒ ìë™ ê²€ì¶œ" ì²´í¬
        - **ìƒì„¸í•œ ì„¤ëª…**: ì˜·ì˜ ìƒ‰ìƒ, ìŠ¤íƒ€ì¼, ì•¡ì„¸ì„œë¦¬ë¥¼ êµ¬ì²´ì ìœ¼ë¡œ ì‘ì„±

        ### ê¸°ìˆ  ì •ë³´

        - **ëª¨ë¸**: SigLIP (Google Sigmoid Loss Vision-Language Model)
        - **ê²€ì¶œê¸°**: YOLOv8 (ì‹¤ì‹œê°„ ê°ì²´ ê²€ì¶œ)
        - **ì„ë² ë”© ì°¨ì›**: 768
        - **ì§€ì› ì–¸ì–´**: í•œêµ­ì–´, ì˜ì–´
        """)


if __name__ == "__main__":
    print("\n" + "=" * 60)
    print("ğŸš€ Starting SigLIP Person Finder Web UI")
    print("=" * 60 + "\n")

    demo.launch(
        server_name="0.0.0.0",
        server_port=7860,
        share=False,  # Set to True to create public link
        show_error=True
    )
