"""
Streamlit Web UI for SigLIP Person Finder
Interactive interface for text-based person search

Usage:
    streamlit run app_streamlit.py
"""

import streamlit as st
import numpy as np
from PIL import Image
import cv2
from typing import List
import logging

from model import SigLIPPersonFinder
from video_pipeline import PersonSearchPipeline

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


# Page config
st.set_page_config(
    page_title="SigLIP Person Finder",
    page_icon="ğŸ”",
    layout="wide",
    initial_sidebar_state="expanded"
)


@st.cache_resource
def load_models():
    """Load models once and cache"""
    finder = SigLIPPersonFinder()
    pipeline = PersonSearchPipeline(siglip_model=finder)
    return finder, pipeline


def main():
    st.title("ğŸ” SigLIP Person Finder")
    st.markdown("""
    í…ìŠ¤íŠ¸ ê¸°ë°˜ ì¸ë¬¼ ê²€ìƒ‰ ì‹œìŠ¤í…œ - ìì—°ì–´ ì„¤ëª…ë§Œìœ¼ë¡œ ì‚¬ì§„ì´ë‚˜ ì˜ìƒì—ì„œ ì‚¬ëŒì„ ì°¾ì•„ëƒ…ë‹ˆë‹¤!
    """)

    # Sidebar
    with st.sidebar:
        st.header("âš™ï¸ ì„¤ì •")

        threshold = st.slider(
            "ìœ ì‚¬ë„ ì„ê³„ê°’",
            min_value=0.0,
            max_value=1.0,
            value=0.30,
            step=0.05,
            help="ë‚®ì„ìˆ˜ë¡ ë” ë§ì€ ê²°ê³¼, ë†’ì„ìˆ˜ë¡ ë” ì •í™•í•œ ê²°ê³¼"
        )

        detect_persons = st.checkbox(
            "ì‚¬ëŒ ìë™ ê²€ì¶œ (YOLO)",
            value=True,
            help="ì´ë¯¸ì§€ì—ì„œ ì‚¬ëŒì„ ë¨¼ì € ì°¾ì•„ë‚¸ í›„ ê²€ìƒ‰"
        )

        st.divider()

        st.markdown("""
        ### ğŸ“– ì‚¬ìš© ê°€ì´ë“œ

        **ì¢‹ì€ ì¿¼ë¦¬ ì˜ˆì‹œ:**
        - ë‚¨ì, íŒŒë€ìƒ‰ ìƒì˜, ê²€ì€ìƒ‰ ë°”ì§€
        - A man wearing a white shirt
        - ì—¬ì, ë¹¨ê°„ ì¬í‚·, ê¸´ ë¨¸ë¦¬

        **ì„ê³„ê°’ ê°€ì´ë“œ:**
        - 0.25-0.30: ì‹¤ì¢…ì ì°¾ê¸°
        - 0.30-0.35: CCTV ê°ì‹œ
        - 0.40-0.45: ì •ë°€ ê²€ìƒ‰
        """)

    # Main content
    tab1, tab2, tab3 = st.tabs(["ğŸ“¸ ì´ë¯¸ì§€ ê²€ìƒ‰", "ğŸ¥ ë¹„ë””ì˜¤ ê²€ìƒ‰", "â„¹ï¸ ì •ë³´"])

    # Tab 1: Image Search
    with tab1:
        st.header("ğŸ“¸ ì´ë¯¸ì§€ì—ì„œ ì¸ë¬¼ ê²€ìƒ‰")

        col1, col2 = st.columns([1, 2])

        with col1:
            text_query = st.text_area(
                "ì¸ìƒì°©ì˜ ì„¤ëª…",
                placeholder="ì˜ˆ: íŒŒë€ìƒ‰ ìƒì˜ë¥¼ ì…ì€ ë‚¨ì, ê²€ì€ìƒ‰ ë°”ì§€",
                height=100
            )

            st.markdown("**ì˜ˆì‹œ ì¿¼ë¦¬:**")
            example_queries = [
                "ë‚¨ì, íŒŒë€ìƒ‰ ìƒì˜, ê²€ì€ìƒ‰ ë°”ì§€",
                "A man wearing a white t-shirt",
                "ì—¬ì, ë¹¨ê°„ìƒ‰ ì¬í‚·",
                "A person with a blue backpack"
            ]

            for query in example_queries:
                if st.button(query, key=f"ex_{query}"):
                    text_query = query
                    st.rerun()

        with col2:
            uploaded_files = st.file_uploader(
                "ì´ë¯¸ì§€ ì—…ë¡œë“œ (ì—¬ëŸ¬ ì¥ ê°€ëŠ¥)",
                type=["jpg", "jpeg", "png"],
                accept_multiple_files=True
            )

        if st.button("ğŸ” ê²€ìƒ‰", type="primary", use_container_width=True):
            if not text_query or not text_query.strip():
                st.warning("âš ï¸ í…ìŠ¤íŠ¸ ì¿¼ë¦¬ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”!")
            elif not uploaded_files:
                st.warning("âš ï¸ ì´ë¯¸ì§€ë¥¼ ì—…ë¡œë“œí•´ì£¼ì„¸ìš”!")
            else:
                with st.spinner("ê²€ìƒ‰ ì¤‘..."):
                    try:
                        # Load models
                        finder, pipeline = load_models()

                        # Load images
                        images = [Image.open(f) for f in uploaded_files]

                        if detect_persons:
                            # Detect persons first
                            all_crops = []
                            crop_info = []

                            for img_idx, img in enumerate(images):
                                img_cv = cv2.cvtColor(np.array(img), cv2.COLOR_RGB2BGR)
                                bboxes = pipeline.detect_persons(img_cv)

                                for bbox_idx, bbox in enumerate(bboxes):
                                    crop = pipeline.crop_person(img_cv, bbox)
                                    if crop is not None:
                                        all_crops.append(crop)
                                        crop_info.append({
                                            'image_idx': img_idx,
                                            'bbox_idx': bbox_idx,
                                            'filename': uploaded_files[img_idx].name
                                        })

                            if not all_crops:
                                st.error("âš ï¸ ì´ë¯¸ì§€ì—ì„œ ì‚¬ëŒì„ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤!")
                                return

                            # Search
                            results = finder.search(
                                text_query=text_query,
                                images=all_crops,
                                threshold=threshold
                            )

                            # Display results
                            if not results:
                                st.error(f"âŒ ë§¤ì¹­ë˜ëŠ” ì‚¬ëŒì„ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤ (ì„ê³„ê°’: {threshold:.2f})")
                            else:
                                st.success(f"âœ… {len(results)}ëª…ì˜ ë§¤ì¹­ì„ ì°¾ì•˜ìŠµë‹ˆë‹¤!")

                                cols = st.columns(4)
                                for idx, result in enumerate(results):
                                    crop = result['image']
                                    sim = result['similarity']
                                    info = crop_info[result['index']]

                                    with cols[idx % 4]:
                                        st.image(crop, use_column_width=True)
                                        st.caption(f"ìœ ì‚¬ë„: {sim:.3f}")
                                        st.caption(f"íŒŒì¼: {info['filename']}")
                                        st.caption(f"ì‚¬ëŒ #{info['bbox_idx']+1}")

                        else:
                            # Direct search
                            results = finder.search(
                                text_query=text_query,
                                images=images,
                                threshold=threshold
                            )

                            if not results:
                                st.error(f"âŒ ë§¤ì¹­ë˜ëŠ” ì´ë¯¸ì§€ë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤ (ì„ê³„ê°’: {threshold:.2f})")
                            else:
                                st.success(f"âœ… {len(results)}ê°œì˜ ë§¤ì¹­ì„ ì°¾ì•˜ìŠµë‹ˆë‹¤!")

                                cols = st.columns(4)
                                for idx, result in enumerate(results):
                                    img = result['image']
                                    sim = result['similarity']

                                    with cols[idx % 4]:
                                        st.image(img, use_column_width=True)
                                        st.caption(f"ìœ ì‚¬ë„: {sim:.3f}")
                                        st.caption(f"íŒŒì¼: {uploaded_files[result['index']].name}")

                    except Exception as e:
                        st.error(f"âŒ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
                        logger.error(f"Search error: {e}", exc_info=True)

    # Tab 2: Video Search
    with tab2:
        st.header("ğŸ¥ ë¹„ë””ì˜¤ì—ì„œ ì¸ë¬¼ ê²€ìƒ‰")

        col1, col2 = st.columns([1, 1])

        with col1:
            video_query = st.text_area(
                "ì¸ìƒì°©ì˜ ì„¤ëª…",
                placeholder="ì˜ˆ: í°ìƒ‰ ì…”ì¸ ë¥¼ ì…ì€ ë‚¨ì",
                height=100,
                key="video_query"
            )

            frame_skip = st.slider(
                "í”„ë ˆì„ ìŠ¤í‚µ",
                min_value=1,
                max_value=30,
                value=5,
                help="N í”„ë ˆì„ë§ˆë‹¤ ì²˜ë¦¬ (ë†’ì„ìˆ˜ë¡ ë¹ ë¦„)"
            )

            max_results = st.slider(
                "ìµœëŒ€ ê²°ê³¼ ìˆ˜",
                min_value=1,
                max_value=50,
                value=10
            )

        with col2:
            video_file = st.file_uploader(
                "ë¹„ë””ì˜¤ ì—…ë¡œë“œ",
                type=["mp4", "avi", "mov"]
            )

        if st.button("ğŸ” ë¹„ë””ì˜¤ ê²€ìƒ‰", type="primary", use_container_width=True, key="video_search"):
            if not video_query or not video_query.strip():
                st.warning("âš ï¸ í…ìŠ¤íŠ¸ ì¿¼ë¦¬ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”!")
            elif not video_file:
                st.warning("âš ï¸ ë¹„ë””ì˜¤ë¥¼ ì—…ë¡œë“œí•´ì£¼ì„¸ìš”!")
            else:
                with st.spinner("ë¹„ë””ì˜¤ ê²€ìƒ‰ ì¤‘... (ì‹œê°„ì´ ê±¸ë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤)"):
                    try:
                        # Save video temporarily
                        import tempfile
                        with tempfile.NamedTemporaryFile(delete=False, suffix='.mp4') as tmp_file:
                            tmp_file.write(video_file.read())
                            tmp_path = tmp_file.name

                        # Load models
                        finder, pipeline = load_models()
                        pipeline.similarity_threshold = threshold
                        pipeline.frame_skip = frame_skip

                        # Search
                        results = pipeline.search_in_video(
                            video_path=tmp_path,
                            text_query=video_query,
                            max_results=max_results,
                            save_results=False
                        )

                        # Clean up
                        import os
                        os.unlink(tmp_path)

                        if not results:
                            st.error(f"âŒ ë¹„ë””ì˜¤ì—ì„œ ë§¤ì¹­ì„ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤ (ì„ê³„ê°’: {threshold:.2f})")
                        else:
                            st.success(f"âœ… {len(results)}ê°œì˜ ë§¤ì¹­ì„ ì°¾ì•˜ìŠµë‹ˆë‹¤!")

                            cols = st.columns(4)
                            for idx, result in enumerate(results):
                                crop = result['person_crop']
                                sim = result['similarity']
                                timestamp = result['timestamp']
                                frame = result['frame_idx']

                                with cols[idx % 4]:
                                    st.image(crop, use_column_width=True)
                                    st.caption(f"ìœ ì‚¬ë„: {sim:.3f}")
                                    st.caption(f"ì‹œê°„: {timestamp:.2f}ì´ˆ")
                                    st.caption(f"í”„ë ˆì„: {frame}")

                    except Exception as e:
                        st.error(f"âŒ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
                        logger.error(f"Video search error: {e}", exc_info=True)

    # Tab 3: Info
    with tab3:
        st.header("â„¹ï¸ í”„ë¡œì íŠ¸ ì •ë³´")

        st.markdown("""
        ## SigLIP Person Finder

        í…ìŠ¤íŠ¸ ê¸°ë°˜ ì¸ë¬¼ ê²€ìƒ‰ ì‹œìŠ¤í…œ

        ### íŠ¹ì§•
        - **í…ìŠ¤íŠ¸ ê¸°ë°˜ ê²€ìƒ‰**: ìì—°ì–´ë¡œ ì¸ë¬¼ ê²€ìƒ‰
        - **ë©€í‹°ëª¨ë‹¬ AI**: SigLIP (Google) ê¸°ë°˜
        - **ì‹¤ì‹œê°„ ì²˜ë¦¬**: YOLOv8 + SigLIP
        - **í•œêµ­ì–´ ì§€ì›**: í•œêµ­ì–´/ì˜ì–´ ëª¨ë‘ ì§€ì›

        ### ê¸°ìˆ  ìŠ¤íƒ
        - **SigLIP**: Google Sigmoid Loss Vision-Language Model
        - **YOLOv8**: ì‹¤ì‹œê°„ ê°ì²´ ê²€ì¶œ
        - **Transformers**: HuggingFace
        - **PyTorch**: ë”¥ëŸ¬ë‹ í”„ë ˆì„ì›Œí¬
        - **Streamlit**: ì›¹ UI

        ### ì„±ëŠ¥
        - Recall@1: 0.362
        - Recall@5: 0.681
        - Recall@10: 0.810

        ### ëª¨ë¸ ì •ë³´
        - **ëª¨ë¸**: `adonaivera/siglip-person-search-openset`
        - **ì„ë² ë”© ì°¨ì›**: 768
        - **í›ˆë ¨ ë°ì´í„°**: ReID ë°ì´í„°ì…‹
        """)


if __name__ == "__main__":
    main()
