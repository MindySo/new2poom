"""
ìµœì í™”ëœ ì‹¤ì¢…ì íƒì§€ ì‹œìŠ¤í…œ (ONNX ê¸°ë°˜ + React ìŠ¤íƒ€ì¼)
- 3-5ë°° ë¹ ë¥¸ ì²˜ë¦¬ ì†ë„
- í”„ë ˆì„ ìŠ¤í‚µ ì˜µì…˜
- í•´ìƒë„ ì¡°ì • ì˜µì…˜
- GPU ê°€ì† ì§€ì›
- React-inspired UI/UX
"""

import streamlit as st
import cv2
import numpy as np
from PIL import Image
import tempfile
import os
import time
from missing_person_detector_onnx import MissingPersonDetectorONNX


def load_custom_css():
    """React ìŠ¤íƒ€ì¼ CSS ì ìš©"""
    st.markdown("""
    <style>
    /* ì „ì—­ ë³€ìˆ˜ */
    :root {
        --primary-color: #1D70D5;
        --primary-hover: #1557A8;
        --background-color: #111827;
        --card-bg: rgba(17, 24, 39, 0.7);
        --card-border: rgba(255, 255, 255, 0.1);
        --text-primary: #ffffff;
        --text-secondary: rgba(255, 255, 255, 0.7);
        --success-color: #10b981;
        --warning-color: #f59e0b;
        --error-color: #ef4444;
    }

    /* ì „ì²´ ë°°ê²½ - ë‹¤í¬ ê·¸ë¼ë””ì–¸íŠ¸ */
    .stApp {
        background: linear-gradient(135deg, #111827, #000, #0f172a);
        color: var(--text-primary);
        font-family: 'Inter', -apple-system, BlinkMacSystemFont, 'Segoe UI', sans-serif;
    }

    /* ì‚¬ì´ë“œë°” ìŠ¤íƒ€ì¼ */
    [data-testid="stSidebar"] {
        background: linear-gradient(180deg, rgba(17, 24, 39, 0.95), rgba(0, 0, 0, 0.95));
        backdrop-filter: blur(10px);
        border-right: 1px solid var(--card-border);
    }

    [data-testid="stSidebar"] [data-testid="stMarkdownContainer"] h1,
    [data-testid="stSidebar"] [data-testid="stMarkdownContainer"] h2,
    [data-testid="stSidebar"] [data-testid="stMarkdownContainer"] h3 {
        color: var(--text-primary);
        font-weight: 600;
    }

    /* ë©”ì¸ íƒ€ì´í‹€ */
    h1 {
        background: linear-gradient(135deg, #1D70D5, #60a5fa);
        -webkit-background-clip: text;
        -webkit-text-fill-color: transparent;
        font-weight: 700;
        font-size: 2.5rem !important;
        margin-bottom: 0.5rem !important;
    }

    /* ì„œë¸Œ íƒ€ì´í‹€ */
    h2, h3 {
        color: var(--text-primary);
        font-weight: 600;
    }

    /* ì¹´ë“œ ìŠ¤íƒ€ì¼ */
    .element-container {
        background: var(--card-bg);
        backdrop-filter: blur(10px);
        border-radius: 12px;
        border: 1px solid var(--card-border);
        padding: 1rem;
        margin: 0.5rem 0;
    }

    /* ë²„íŠ¼ ìŠ¤íƒ€ì¼ */
    .stButton > button {
        background: linear-gradient(135deg, var(--primary-color), #2563eb) !important;
        color: white !important;
        border: none !important;
        border-radius: 8px !important;
        padding: 0.75rem 2rem !important;
        font-weight: 600 !important;
        font-size: 1rem !important;
        transition: all 0.3s ease !important;
        box-shadow: 0 4px 12px rgba(29, 112, 213, 0.3) !important;
    }

    .stButton > button:hover {
        background: linear-gradient(135deg, var(--primary-hover), #1d4ed8) !important;
        transform: translateY(-2px) !important;
        box-shadow: 0 6px 20px rgba(29, 112, 213, 0.4) !important;
    }

    .stButton > button:active {
        transform: translateY(0) !important;
    }

    /* ì…ë ¥ í•„ë“œ */
    .stTextInput > div > div > input,
    .stSelectbox > div > div > select,
    .stFileUploader > div > div {
        background: rgba(30, 41, 59, 0.5) !important;
        border: 1px solid var(--card-border) !important;
        border-radius: 8px !important;
        color: var(--text-primary) !important;
        padding: 0.75rem !important;
    }

    .stTextInput > div > div > input:focus,
    .stSelectbox > div > div > select:focus {
        border-color: var(--primary-color) !important;
        box-shadow: 0 0 0 2px rgba(29, 112, 213, 0.2) !important;
    }

    /* ìŠ¬ë¼ì´ë” */
    .stSlider > div > div > div {
        background: rgba(30, 41, 59, 0.5) !important;
    }

    .stSlider > div > div > div > div {
        background: var(--primary-color) !important;
    }

    /* ì²´í¬ë°•ìŠ¤ & ë¼ë””ì˜¤ */
    .stCheckbox, .stRadio {
        color: var(--text-primary) !important;
    }

    /* ë©”íŠ¸ë¦­ ì¹´ë“œ */
    [data-testid="stMetricValue"] {
        color: var(--primary-color) !important;
        font-size: 2rem !important;
        font-weight: 700 !important;
    }

    [data-testid="stMetricLabel"] {
        color: var(--text-secondary) !important;
        font-size: 0.9rem !important;
    }

    /* ì„±ê³µ ë©”ì‹œì§€ */
    .stSuccess {
        background: rgba(16, 185, 129, 0.1) !important;
        border: 1px solid rgba(16, 185, 129, 0.3) !important;
        border-radius: 8px !important;
        color: var(--success-color) !important;
    }

    /* ê²½ê³  ë©”ì‹œì§€ */
    .stWarning {
        background: rgba(245, 158, 11, 0.1) !important;
        border: 1px solid rgba(245, 158, 11, 0.3) !important;
        border-radius: 8px !important;
        color: var(--warning-color) !important;
    }

    /* ì—ëŸ¬ ë©”ì‹œì§€ */
    .stError {
        background: rgba(239, 68, 68, 0.1) !important;
        border: 1px solid rgba(239, 68, 68, 0.3) !important;
        border-radius: 8px !important;
        color: var(--error-color) !important;
    }

    /* ì •ë³´ ë©”ì‹œì§€ */
    .stInfo {
        background: rgba(29, 112, 213, 0.1) !important;
        border: 1px solid rgba(29, 112, 213, 0.3) !important;
        border-radius: 8px !important;
        color: var(--primary-color) !important;
    }

    /* í”„ë¡œê·¸ë ˆìŠ¤ ë°” */
    .stProgress > div > div > div {
        background: var(--primary-color) !important;
        border-radius: 8px !important;
    }

    /* íŒŒì¼ ì—…ë¡œë” */
    [data-testid="stFileUploader"] {
        background: rgba(30, 41, 59, 0.3) !important;
        border: 2px dashed var(--card-border) !important;
        border-radius: 12px !important;
        padding: 2rem !important;
        transition: all 0.3s ease !important;
    }

    [data-testid="stFileUploader"]:hover {
        border-color: var(--primary-color) !important;
        background: rgba(29, 112, 213, 0.05) !important;
    }

    /* Expander */
    .streamlit-expanderHeader {
        background: rgba(30, 41, 59, 0.5) !important;
        border-radius: 8px !important;
        color: var(--text-primary) !important;
        font-weight: 600 !important;
    }

    .streamlit-expanderHeader:hover {
        background: rgba(30, 41, 59, 0.7) !important;
    }

    /* ë‹¤ìš´ë¡œë“œ ë²„íŠ¼ */
    .stDownloadButton > button {
        background: linear-gradient(135deg, var(--success-color), #059669) !important;
        color: white !important;
        border: none !important;
        border-radius: 8px !important;
        font-weight: 600 !important;
    }

    .stDownloadButton > button:hover {
        background: linear-gradient(135deg, #059669, #047857) !important;
        transform: translateY(-2px) !important;
    }

    /* ë¹„ë””ì˜¤ í”Œë ˆì´ì–´ */
    video {
        border-radius: 12px !important;
        box-shadow: 0 8px 32px rgba(0, 0, 0, 0.4) !important;
    }

    /* ì´ë¯¸ì§€ */
    img {
        border-radius: 8px !important;
    }

    /* ì½”ë“œ ë¸”ë¡ */
    code {
        background: rgba(30, 41, 59, 0.5) !important;
        border-radius: 4px !important;
        color: #60a5fa !important;
        padding: 0.2rem 0.4rem !important;
    }

    pre {
        background: rgba(15, 23, 42, 0.8) !important;
        border: 1px solid var(--card-border) !important;
        border-radius: 8px !important;
        padding: 1rem !important;
    }

    /* êµ¬ë¶„ì„  */
    hr {
        border: none !important;
        border-top: 1px solid var(--card-border) !important;
        margin: 2rem 0 !important;
    }

    /* ìº¡ì…˜ */
    .caption {
        color: var(--text-secondary) !important;
        font-size: 0.875rem !important;
    }

    /* ìŠ¤í¬ë¡¤ë°” */
    ::-webkit-scrollbar {
        width: 10px;
        height: 10px;
    }

    ::-webkit-scrollbar-track {
        background: rgba(15, 23, 42, 0.5);
        border-radius: 10px;
    }

    ::-webkit-scrollbar-thumb {
        background: rgba(29, 112, 213, 0.5);
        border-radius: 10px;
    }

    ::-webkit-scrollbar-thumb:hover {
        background: rgba(29, 112, 213, 0.7);
    }
    </style>
    """, unsafe_allow_html=True)


def main():
    st.set_page_config(
        page_title="ì‹¤ì¢…ì íƒì§€ ì‹œìŠ¤í…œ (ONNX ìµœì í™”)",
        page_icon="âš¡",
        layout="wide"
    )

    # React ìŠ¤íƒ€ì¼ CSS ì ìš©
    load_custom_css()

    st.title("âš¡ ì‹¤ì¢…ì ì‹¤ì‹œê°„ íƒì§€ ì‹œìŠ¤í…œ (ONNX ìµœì í™”)")
    st.caption("ğŸš€ PyTorch ëŒ€ë¹„ 3-5ë°° ë¹ ë¥¸ ì²˜ë¦¬ ì†ë„ | ONNX Runtime")
    st.markdown("---")

    # ì‚¬ì´ë“œë°”
    with st.sidebar:
        st.header("âš™ï¸ ì„¤ì •")

        # ONNX íŒŒì¼ í™•ì¸
        yolo_exists = os.path.exists('yolov8n.onnx')
        osnet_exists = os.path.exists('osnet_x1_0.onnx')

        if not yolo_exists or not osnet_exists:
            st.error("âŒ ONNX ëª¨ë¸ì´ ì—†ìŠµë‹ˆë‹¤!")
            st.warning("ë¨¼ì € ë‹¤ìŒ ëª…ë ¹ì„ ì‹¤í–‰í•˜ì„¸ìš”:")
            st.code("python convert_to_onnx.py", language="bash")
            st.stop()
        else:
            st.success("âœ… ONNX ëª¨ë¸ ì¤€ë¹„ ì™„ë£Œ")

        st.markdown("---")

        # ì‹¤ì¢…ì ì´ë¯¸ì§€ ì—…ë¡œë“œ
        st.subheader("1ï¸âƒ£ ì‹¤ì¢…ì ì´ë¯¸ì§€")
        uploaded_images = st.file_uploader(
            "ì‹¤ì¢…ì ì‚¬ì§„ì„ ì—…ë¡œë“œí•˜ì„¸ìš” (ì—¬ëŸ¬ ì¥ ê¶Œì¥)",
            type=['jpg', 'jpeg', 'png'],
            accept_multiple_files=True,
            help="ë‹¤ì–‘í•œ ê°ë„/ì¡°ëª…ì˜ ì‚¬ì§„ì„ ì—¬ëŸ¬ ì¥ ì—…ë¡œë“œí•˜ë©´ ì •í™•ë„ê°€ í–¥ìƒë©ë‹ˆë‹¤"
        )

        if uploaded_images:
            st.write(f"ğŸ“¸ ì—…ë¡œë“œëœ ì´ë¯¸ì§€: {len(uploaded_images)}ì¥")
            cols = st.columns(min(len(uploaded_images), 3))
            for idx, uploaded_image in enumerate(uploaded_images):
                with cols[idx % 3]:
                    image = Image.open(uploaded_image).convert('RGB')
                    st.image(image, caption=f"ì´ë¯¸ì§€ {idx+1}", use_container_width=True)

        st.markdown("---")

        # ì…ë ¥ ì†ŒìŠ¤ ì„ íƒ
        st.subheader("2ï¸âƒ£ ì…ë ¥ ì†ŒìŠ¤")
        input_source = st.radio(
            "ì…ë ¥ ì†ŒìŠ¤ë¥¼ ì„ íƒí•˜ì„¸ìš”",
            ["ğŸ“ ë¹„ë””ì˜¤ íŒŒì¼", "ğŸ“· ì›¹ìº  (ì‹¤ì‹œê°„)"],
            help="ë¹„ë””ì˜¤ íŒŒì¼ ë˜ëŠ” ì›¹ìº  ì¤‘ ì„ íƒí•˜ì„¸ìš”"
        )

        uploaded_video = None
        camera_index = 0
        max_duration = None

        if input_source == "ğŸ“ ë¹„ë””ì˜¤ íŒŒì¼":
            # ì˜ìƒ íŒŒì¼ ì—…ë¡œë“œ
            uploaded_video = st.file_uploader(
                "CCTV ì˜ìƒì„ ì—…ë¡œë“œí•˜ì„¸ìš”",
                type=['mp4', 'avi', 'mov'],
                help="ë¶„ì„í•  CCTV ì˜ìƒ íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì„¸ìš”"
            )
        else:
            # ì›¹ìº  ì„¤ì •
            camera_type = st.radio(
                "ì¹´ë©”ë¼ íƒ€ì…",
                ["ğŸ’» PC ì›¹ìº ", "ğŸ“± íœ´ëŒ€í° (IP Webcam)"],
                help="PC ë‚´ì¥ ì¹´ë©”ë¼ ë˜ëŠ” íœ´ëŒ€í° IP ì¹´ë©”ë¼ ì„ íƒ"
            )

            if camera_type == "ğŸ’» PC ì›¹ìº ":
                camera_index = st.selectbox(
                    "ì¹´ë©”ë¼ ì„ íƒ",
                    options=[0, 1, 2],
                    help="ì‚¬ìš©í•  ì¹´ë©”ë¼ ì¸ë±ìŠ¤ (0 = ê¸°ë³¸ ì¹´ë©”ë¼)"
                )
            else:
                # íœ´ëŒ€í° IP ì¹´ë©”ë¼
                st.info("""
                **ğŸ“± IP Webcam ì•± ì‚¬ìš©ë²•:**
                1. íœ´ëŒ€í°ì—ì„œ IP Webcam ì•± ì‹¤í–‰
                2. í•˜ë‹¨ "ì„œë²„ ì‹œì‘" í´ë¦­
                3. í™”ë©´ ìƒë‹¨ì— í‘œì‹œëœ ì£¼ì†Œë¥¼ ì•„ë˜ì— ì…ë ¥
                """)

                ip_input = st.text_input(
                    "IP Webcam ì£¼ì†Œ",
                    value="192.168.0.106:8080",
                    help="ì˜ˆ: 192.168.0.106:8080"
                )

                # http:// ì™€ /video ìë™ ì¶”ê°€
                if ip_input:
                    if not ip_input.startswith('http'):
                        ip_input = 'http://' + ip_input
                    if not ip_input.endswith('/video'):
                        ip_input = ip_input + '/video'

                    camera_index = ip_input
                    st.success(f"âœ… ì—°ê²° ì£¼ì†Œ: `{camera_index}`")
                else:
                    camera_index = "http://192.168.0.106:8080/video"

            st.caption("ğŸ’¡ ì›¹ìº ì€ 'q' í‚¤ë¥¼ ëˆŒëŸ¬ ì¢…ë£Œí•  ë•Œê¹Œì§€ ê³„ì† ì‹¤í–‰ë©ë‹ˆë‹¤")
            max_duration = None  # ë¬´ì œí•œ

        st.markdown("---")

        # íƒì§€ ì„¤ì •
        st.subheader("3ï¸âƒ£ íƒì§€ ì„¤ì •")

        # GPU ì‚¬ìš© ì—¬ë¶€
        use_gpu = st.checkbox(
            "GPU ì‚¬ìš©",
            value=True,
            help="GPUë¥¼ ì‚¬ìš©í•˜ë©´ ë” ë¹ ë¦…ë‹ˆë‹¤ (CUDA í•„ìš”)"
        )

        # ë§¤ì¹­ ì „ëµ
        matching_strategy = st.selectbox(
            "ë§¤ì¹­ ì „ëµ",
            options=['average', 'weighted', 'strict', 'max'],
            index=0,
            help="ì—¬ëŸ¬ ì°¸ì¡° ì´ë¯¸ì§€ë¥¼ ì–´ë–»ê²Œ ë¹„êµí• ì§€ ì„ íƒ"
        )

        strategy_info = {
            'average': 'í‰ê· : ëª¨ë“  ì´ë¯¸ì§€ì˜ í‰ê·  ìœ ì‚¬ë„ (ê¶Œì¥)',
            'weighted': 'ê°€ì¤‘: ìƒìœ„ 3ê°œì˜ í‰ê·  (ê· í˜•)',
            'strict': 'ì—„ê²©: ëª¨ë“  ì´ë¯¸ì§€ê°€ ë†’ì•„ì•¼ í•¨',
            'max': 'ìµœëŒ€: í•˜ë‚˜ë¼ë„ ë†’ìœ¼ë©´ íƒì§€ (ì˜¤íƒ ìœ„í—˜)'
        }
        st.caption(f"âœ“ {strategy_info[matching_strategy]}")

        # ìœ ì‚¬ë„ ì„ê³„ê°’
        similarity_threshold = st.slider(
            "ìœ ì‚¬ë„ ì„ê³„ê°’",
            min_value=0.5,
            max_value=0.95,
            value=0.75,
            step=0.05,
            help="ë†’ì„ìˆ˜ë¡ ì—„ê²©í•˜ê²Œ íƒì§€í•©ë‹ˆë‹¤"
        )

        st.markdown("---")

        # ì„±ëŠ¥ ìµœì í™” ì„¤ì •
        st.subheader("4ï¸âƒ£ ì„±ëŠ¥ ìµœì í™”")

        # í”„ë ˆì„ ìŠ¤í‚µ
        frame_skip = st.slider(
            "í”„ë ˆì„ ìŠ¤í‚µ (ì†ë„ í–¥ìƒ)",
            min_value=0,
            max_value=5,
            value=0,
            step=1,
            help="0=ëª¨ë“  í”„ë ˆì„, 1=1í”„ë ˆì„ ê±´ë„ˆë›°ê¸°, 2=2í”„ë ˆì„ ê±´ë„ˆë›°ê¸°"
        )

        if frame_skip > 0:
            st.caption(f"âš¡ {frame_skip}í”„ë ˆì„ë§ˆë‹¤ ê±´ë„ˆë›°ê¸° â†’ ì•½ {(frame_skip + 1)}ë°° ë¹ ë¦„")
        else:
            st.caption("âœ“ ëª¨ë“  í”„ë ˆì„ ì²˜ë¦¬ (ê°€ì¥ ì •í™•)")

        # í•´ìƒë„ ì¡°ì •
        resize_factor = st.slider(
            "í•´ìƒë„ ì¡°ì • (ë©”ëª¨ë¦¬ ìµœì í™”)",
            min_value=0.25,
            max_value=1.0,
            value=1.0,
            step=0.05,
            help="1.0=ì›ë³¸, 0.5=50% ì¶•ì†Œ, 0.25=25% ì¶•ì†Œ"
        )

        if resize_factor < 1.0:
            st.caption(f"âš¡ í•´ìƒë„ {resize_factor*100:.0f}% â†’ ì•½ {(1/resize_factor)**2:.1f}ë°° ë¹ ë¦„")
        else:
            st.caption("âœ“ ì›ë³¸ í•´ìƒë„ ìœ ì§€ (ê°€ì¥ ì •í™•)")

        # ì˜ˆìƒ ì†ë„ í–¥ìƒ
        total_speedup = 3.0  # ONNX ê¸°ë³¸ ì†ë„ í–¥ìƒ
        if frame_skip > 0:
            total_speedup *= (frame_skip + 1)
        if resize_factor < 1.0:
            total_speedup *= (1 / resize_factor) ** 1.5

        st.info(f"ğŸš€ **ì˜ˆìƒ ì†ë„ í–¥ìƒ**: PyTorch ëŒ€ë¹„ ì•½ **{total_speedup:.1f}ë°°** ë¹ ë¦„")

    # ë©”ì¸ ì˜ì—­
    col1, col2 = st.columns([1, 1])

    with col1:
        st.subheader("ğŸ“‹ ì‹œìŠ¤í…œ ìƒíƒœ")

        if input_source == "ğŸ“ ë¹„ë””ì˜¤ íŒŒì¼":
            if uploaded_images and uploaded_video:
                st.success(f"âœ… ëª¨ë“  íŒŒì¼ì´ ì¤€ë¹„ë˜ì—ˆìŠµë‹ˆë‹¤! (ì‹¤ì¢…ì ì´ë¯¸ì§€: {len(uploaded_images)}ì¥)")

                # ì˜ìƒ ì •ë³´ í‘œì‹œ
                with tempfile.NamedTemporaryFile(delete=False, suffix='.mp4') as tmp_video:
                    tmp_video.write(uploaded_video.read())
                    tmp_video_path = tmp_video.name

                cap = cv2.VideoCapture(tmp_video_path)
                width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
                height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
                fps = int(cap.get(cv2.CAP_PROP_FPS))
                total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
                cap.release()

                # ìµœì í™” í›„ ì˜ˆìƒ í•´ìƒë„
                opt_width = int(width * resize_factor)
                opt_height = int(height * resize_factor)
                opt_frames = total_frames // (frame_skip + 1) if frame_skip > 0 else total_frames

                st.info(f"""
                **ì›ë³¸ ì˜ìƒ ì •ë³´:**
                - í•´ìƒë„: {width}x{height}
                - FPS: {fps}
                - ì´ í”„ë ˆì„: {total_frames}

                **ìµœì í™” í›„:**
                - ì²˜ë¦¬ í•´ìƒë„: {opt_width}x{opt_height}
                - ì²˜ë¦¬ í”„ë ˆì„: {opt_frames}
                - ì˜ˆìƒ ì†Œìš” ì‹œê°„: {opt_frames / (total_speedup * 10):.0f}ì´ˆ
                """)

            elif not uploaded_images:
                st.warning("âš ï¸ ì‹¤ì¢…ì ì´ë¯¸ì§€ë¥¼ ì—…ë¡œë“œí•´ì£¼ì„¸ìš”")
            elif not uploaded_video:
                st.warning("âš ï¸ CCTV ì˜ìƒì„ ì—…ë¡œë“œí•´ì£¼ì„¸ìš”")
        else:
            # ì›¹ìº  ëª¨ë“œ
            if uploaded_images:
                st.success(f"âœ… ì‹¤ì¢…ì ì´ë¯¸ì§€ ì¤€ë¹„ ì™„ë£Œ! ({len(uploaded_images)}ì¥)")

                camera_display = camera_index if isinstance(camera_index, str) else f"ì¹´ë©”ë¼ {camera_index}"
                st.info(f"""
                **ì›¹ìº  ì„¤ì •:**
                - ì¹´ë©”ë¼: {camera_display}
                - ì‹¤í–‰ ì‹œê°„: ë¬´ì œí•œ ('q' í‚¤ë¡œ ì¢…ë£Œ)
                - ìœ ì‚¬ë„ ì„ê³„ê°’: {similarity_threshold}
                - í”„ë ˆì„ ìŠ¤í‚µ: {frame_skip}
                - í•´ìƒë„ ì¡°ì •: {resize_factor * 100:.0f}%
                """)
            else:
                st.warning("âš ï¸ ì‹¤ì¢…ì ì´ë¯¸ì§€ë¥¼ ì—…ë¡œë“œí•´ì£¼ì„¸ìš”")

    with col2:
        st.subheader("ğŸš€ íƒì§€ ì‹œì‘")

        if input_source == "ğŸ“ ë¹„ë””ì˜¤ íŒŒì¼":
            # ë¹„ë””ì˜¤ íŒŒì¼ ì²˜ë¦¬
            if st.button("ğŸ” ì‹¤ì¢…ì íƒì§€ ì‹œì‘ (ONNX ê°€ì†)", type="primary", use_container_width=True):
                if not uploaded_images or not uploaded_video:
                    st.error("âŒ ì´ë¯¸ì§€ì™€ ì˜ìƒì„ ëª¨ë‘ ì—…ë¡œë“œí•´ì£¼ì„¸ìš”!")
                else:
                    try:
                        # ì„ì‹œ íŒŒì¼ ìƒì„±
                        with tempfile.NamedTemporaryFile(delete=False, suffix='.mp4') as tmp_video:
                            uploaded_video.seek(0)
                            tmp_video.write(uploaded_video.read())
                            tmp_video_path = tmp_video.name

                        output_path = tempfile.mktemp(suffix='.mp4')

                        # ONNX íƒì§€ê¸° ì´ˆê¸°í™”
                        with st.spinner("ONNX ëª¨ë¸ ë¡œë”© ì¤‘..."):
                            detector = MissingPersonDetectorONNX(
                                yolo_onnx_path='yolov8n.onnx',
                                osnet_onnx_path='osnet_x1_0.onnx',
                                similarity_threshold=similarity_threshold,
                                matching_strategy=matching_strategy,
                                frame_skip=frame_skip,
                                resize_factor=resize_factor,
                                use_gpu=use_gpu
                            )

                        # ì‹¤ì¢…ì ì´ë¯¸ì§€ ì„¤ì •
                        images = []
                        for uploaded_img in uploaded_images:
                            uploaded_img.seek(0)
                            image = Image.open(uploaded_img).convert('RGB')
                            images.append(image)

                        if len(images) == 1:
                            detector.set_missing_person(images[0])
                        else:
                            detector.set_missing_persons(images)

                        # ì§„í–‰ ìƒí™© í‘œì‹œ
                        progress_bar = st.progress(0)
                        status_text = st.empty()

                        def progress_callback(progress, frame_count, total_frames, fps_current, detection_count):
                            progress_bar.progress(progress)
                            status_text.text(
                                f"âš¡ ì²˜ë¦¬ ì¤‘... {frame_count}/{total_frames} í”„ë ˆì„ | "
                                f"{fps_current:.1f} fps | íƒì§€: {detection_count}íšŒ"
                            )

                        # ì˜ìƒ ì²˜ë¦¬
                        start_time = time.time()
                        with st.spinner("ğŸš€ ì˜ìƒ ì²˜ë¦¬ ì¤‘... (ONNX ê°€ì†)"):
                            results = detector.process_video(
                                tmp_video_path,
                                output_path,
                                progress_callback=progress_callback
                            )

                        processing_time = time.time() - start_time

                        # ê²°ê³¼ í‘œì‹œ
                        st.success("âœ… íƒì§€ ì™„ë£Œ!")

                        col_r1, col_r2, col_r3, col_r4 = st.columns(4)
                        with col_r1:
                            st.metric("ì´ í”„ë ˆì„", f"{results['total_frames']:,}")
                        with col_r2:
                            st.metric("ì²˜ë¦¬ í”„ë ˆì„", f"{results['processed_frames']:,}")
                        with col_r3:
                            st.metric("íƒì§€ íšŸìˆ˜", f"{results['detection_count']:,}")
                        with col_r4:
                            st.metric("í‰ê·  FPS", f"{results['avg_fps']:.1f}")

                        st.info(f"â±ï¸ ì²˜ë¦¬ ì‹œê°„: {processing_time:.1f}ì´ˆ")

                        # ì„±ëŠ¥ ë¹„êµ
                        estimated_pytorch_time = processing_time * total_speedup
                        st.success(
                            f"ğŸš€ **ONNX ê°€ì† íš¨ê³¼**: PyTorchë¡œ í–ˆë‹¤ë©´ ì•½ {estimated_pytorch_time:.1f}ì´ˆ "
                            f"ê±¸ë ¸ì„ ê²ƒì„ {processing_time:.1f}ì´ˆë§Œì— ì™„ë£Œ! "
                            f"(**{total_speedup:.1f}ë°°** ë¹ ë¦„)"
                        )

                        # ê²°ê³¼ ì˜ìƒ í‘œì‹œ
                        st.subheader("ğŸ“¹ ê²°ê³¼ ì˜ìƒ")

                        if os.path.exists(output_path):
                            with open(output_path, 'rb') as f:
                                video_bytes = f.read()

                            st.video(video_bytes)

                            # ë‹¤ìš´ë¡œë“œ ë²„íŠ¼
                            st.download_button(
                                label="â¬‡ï¸ ê²°ê³¼ ì˜ìƒ ë‹¤ìš´ë¡œë“œ",
                                data=video_bytes,
                                file_name=f"detected_onnx_{int(time.time())}.mp4",
                                mime="video/mp4",
                                use_container_width=True
                            )

                            # ì„ì‹œ íŒŒì¼ ì‚­ì œ
                            os.unlink(output_path)

                        os.unlink(tmp_video_path)

                    except Exception as e:
                        st.error(f"âŒ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
                        import traceback
                        st.code(traceback.format_exc())

        else:
            # ì›¹ìº  ì‹¤ì‹œê°„ íƒì§€
            if st.button("ğŸ“· ì›¹ìº  íƒì§€ ì‹œì‘ (ONNX)", type="primary", use_container_width=True):
                if not uploaded_images:
                    st.error("âŒ ì‹¤ì¢…ì ì´ë¯¸ì§€ë¥¼ ì—…ë¡œë“œí•´ì£¼ì„¸ìš”!")
                else:
                    st.warning("âš ï¸ ì›¹ìº ì´ ìƒˆ ì°½ì—ì„œ ì—´ë¦½ë‹ˆë‹¤. 'q' í‚¤ë¥¼ ëˆŒëŸ¬ ì¢…ë£Œí•˜ì„¸ìš”.")
                    st.info("ğŸ’¡ Streamlitì—ì„œëŠ” ì›¹ìº ì„ ì§ì ‘ í‘œì‹œí•  ìˆ˜ ì—†ì–´ OpenCV ì°½ì´ ì—´ë¦½ë‹ˆë‹¤.")

                    try:
                        # ONNX íƒì§€ê¸° ì´ˆê¸°í™”
                        with st.spinner("ONNX ëª¨ë¸ ë¡œë”© ì¤‘..."):
                            detector = MissingPersonDetectorONNX(
                                yolo_onnx_path='yolov8n.onnx',
                                osnet_onnx_path='osnet_x1_0.onnx',
                                similarity_threshold=similarity_threshold,
                                matching_strategy=matching_strategy,
                                frame_skip=frame_skip,
                                resize_factor=resize_factor,
                                use_gpu=use_gpu
                            )

                        # ì‹¤ì¢…ì ì´ë¯¸ì§€ ì„¤ì •
                        images = []
                        for uploaded_img in uploaded_images:
                            uploaded_img.seek(0)
                            image = Image.open(uploaded_img).convert('RGB')
                            images.append(image)

                        if len(images) == 1:
                            detector.set_missing_person(images[0])
                        else:
                            detector.set_missing_persons(images)

                        st.success("âœ… ì›¹ìº  íƒì§€ ì‹œì‘! (OpenCV ì°½ í™•ì¸)")

                        # ì›¹ìº  ì²˜ë¦¬
                        results = detector.process_webcam(
                            camera_index=camera_index,
                            max_duration=max_duration
                        )

                        # ê²°ê³¼ í‘œì‹œ
                        st.success("âœ… ì›¹ìº  íƒì§€ ì™„ë£Œ!")

                        col_r1, col_r2, col_r3 = st.columns(3)
                        with col_r1:
                            st.metric("ì²˜ë¦¬ í”„ë ˆì„", f"{results['frame_count']:,}")
                        with col_r2:
                            st.metric("íƒì§€ íšŸìˆ˜", f"{results['detection_count']:,}")
                        with col_r3:
                            st.metric("í‰ê·  FPS", f"{results['avg_fps']:.1f}")

                        st.info(f"â±ï¸ ì‹¤í–‰ ì‹œê°„: {results['elapsed_time']:.1f}ì´ˆ")

                        if results['detection_count'] > 0:
                            st.warning(f"âš ï¸ **ê²½ê³ **: ì‹¤ì¢…ìê°€ {results['detection_count']}íšŒ íƒì§€ë˜ì—ˆìŠµë‹ˆë‹¤!")

                    except Exception as e:
                        st.error(f"âŒ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
                        import traceback
                        st.code(traceback.format_exc())

    # í•˜ë‹¨ ì •ë³´
    st.markdown("---")
    with st.expander("â„¹ï¸ ì‚¬ìš© ë°©ë²• ë° ìµœì í™” ê°€ì´ë“œ"):
        st.markdown("""
        ## ğŸ“ ê¸°ë³¸ ì‚¬ìš©ë²•
        1. **ì™¼ìª½ ì‚¬ì´ë“œë°”**ì—ì„œ ì‹¤ì¢…ì ì´ë¯¸ì§€ ì—…ë¡œë“œ (ì—¬ëŸ¬ ì¥ ê¶Œì¥)
        2. CCTV ì˜ìƒ íŒŒì¼ ì—…ë¡œë“œ (mp4, avi, mov)
        3. íƒì§€ ì„¤ì • ë° ì„±ëŠ¥ ìµœì í™” ì˜µì…˜ ì¡°ì •
        4. **íƒì§€ ì‹œì‘** ë²„íŠ¼ í´ë¦­
        5. ê²°ê³¼ ì˜ìƒ í™•ì¸ ë° ë‹¤ìš´ë¡œë“œ

        ## âš¡ ì„±ëŠ¥ ìµœì í™” ê°€ì´ë“œ

        ### í”„ë ˆì„ ìŠ¤í‚µ
        - **0**: ëª¨ë“  í”„ë ˆì„ ì²˜ë¦¬ (ê°€ì¥ ì •í™•, ëŠë¦¼)
        - **1**: 1í”„ë ˆì„ ê±´ë„ˆë›°ê¸° (2ë°° ë¹ ë¦„, ì •í™•ë„ 90%)
        - **2**: 2í”„ë ˆì„ ê±´ë„ˆë›°ê¸° (3ë°° ë¹ ë¦„, ì •í™•ë„ 80%)
        - **ê¶Œì¥**: ë¹ ë¥¸ ì›€ì§ì„ì´ ì—†ëŠ” CCTVëŠ” 1-2 ì¶”ì²œ

        ### í•´ìƒë„ ì¡°ì •
        - **1.0**: ì›ë³¸ í•´ìƒë„ ìœ ì§€ (ê°€ì¥ ì •í™•)
        - **0.75**: 75% ì¶•ì†Œ (1.7ë°° ë¹ ë¦„, ì •í™•ë„ 95%)
        - **0.5**: 50% ì¶•ì†Œ (4ë°° ë¹ ë¦„, ì •í™•ë„ 85%)
        - **ê¶Œì¥**: ê³ í•´ìƒë„ ì˜ìƒ(1080p ì´ìƒ)ì€ 0.75 ì¶”ì²œ

        ### GPU ì‚¬ìš©
        - **í™œì„±í™”**: CUDA GPU ì‚¬ìš© (3-5ë°° ë¹ ë¦„)
        - **ë¹„í™œì„±í™”**: CPUë§Œ ì‚¬ìš© (ëŠë¦¬ì§€ë§Œ ì•ˆì •ì )
        - **ê¶Œì¥**: GPUê°€ ìˆìœ¼ë©´ ë°˜ë“œì‹œ í™œì„±í™”

        ## ğŸ¯ ìµœì  ì„¤ì • ì˜ˆì‹œ

        ### ë¹ ë¥¸ ì²˜ë¦¬ (5-10ë°° ì†ë„ í–¥ìƒ)
        - í”„ë ˆì„ ìŠ¤í‚µ: 2
        - í•´ìƒë„: 0.5
        - GPU: í™œì„±í™”
        - ìš©ë„: ëŒ€ìš©ëŸ‰ ì˜ìƒ ë¹ ë¥¸ ìŠ¤ìº”

        ### ê· í˜•ì¡íŒ ì„¤ì • (3-5ë°° ì†ë„ í–¥ìƒ)
        - í”„ë ˆì„ ìŠ¤í‚µ: 1
        - í•´ìƒë„: 0.75
        - GPU: í™œì„±í™”
        - ìš©ë„: ì¼ë°˜ì ì¸ CCTV ë¶„ì„ (ê¶Œì¥)

        ### ì •í™•í•œ ì²˜ë¦¬ (3ë°° ì†ë„ í–¥ìƒ)
        - í”„ë ˆì„ ìŠ¤í‚µ: 0
        - í•´ìƒë„: 1.0
        - GPU: í™œì„±í™”
        - ìš©ë„: ì¤‘ìš”í•œ ì˜ìƒ, ê³ ì •ë°€ íƒì§€ í•„ìš”

        ## ğŸ’¡ íŒ
        - ONNXë§Œìœ¼ë¡œë„ PyTorch ëŒ€ë¹„ 3ë°° ë¹ ë¦„
        - í”„ë ˆì„ ìŠ¤í‚µ + í•´ìƒë„ ì¡°ì •ìœ¼ë¡œ ìµœëŒ€ 10ë°° ì´ìƒ ê°€ì† ê°€ëŠ¥
        - ì‹¤ì‹œê°„ CCTVëŠ” í”„ë ˆì„ ìŠ¤í‚µ 1-2 ê¶Œì¥ (ì‚¬ëŒì´ í¬ê²Œ ì›€ì§ì´ì§€ ì•ŠìŒ)
        - GPUê°€ ì—†ì–´ë„ ONNX CPUê°€ PyTorch CPUë³´ë‹¤ 2-3ë°° ë¹ ë¦„
        """)

    with st.expander("âš™ï¸ ê¸°ìˆ  ì •ë³´"):
        st.markdown("""
        ### ONNX ìµœì í™” ê¸°ìˆ 
        - **ONNX Runtime**: ë”¥ëŸ¬ë‹ ëª¨ë¸ ì¶”ë¡  ìµœì í™” ì—”ì§„
        - **Graph Optimization**: ê³„ì‚° ê·¸ë˜í”„ ìµœì í™”
        - **Quantization Ready**: INT8 ì–‘ìí™” ì§€ì› (ì¶”ê°€ 2ë°° ì†ë„ í–¥ìƒ ê°€ëŠ¥)
        - **Multi-threading**: CPU ë³‘ë ¬ ì²˜ë¦¬

        ### ì„±ëŠ¥ í–¥ìƒ ìš”ì•½
        - YOLOv8: PyTorch ëŒ€ë¹„ 2-3ë°° ë¹ ë¦„
        - OSNet: PyTorch ëŒ€ë¹„ 1.5-2ë°° ë¹ ë¦„
        - ì „ì²´: ì•½ 3ë°° ê¸°ë³¸ ì†ë„ í–¥ìƒ (GPU ê¸°ì¤€)

        ### ì‹œìŠ¤í…œ ìš”êµ¬ì‚¬í•­
        - CPU: ëª¨ë“  í”„ë¡œì„¸ì„œ ì§€ì› (AVX2 ê¶Œì¥)
        - GPU: NVIDIA GPU + CUDA (ì„ íƒì‚¬í•­, í° ì†ë„ í–¥ìƒ)
        - RAM: 4GB ì´ìƒ (8GB ê¶Œì¥)
        - VRAM: 2GB ì´ìƒ (GPU ì‚¬ìš© ì‹œ)
        """)


if __name__ == "__main__":
    main()
