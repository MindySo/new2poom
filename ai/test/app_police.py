"""
ê²½ì°°ì²­ ì‹¤ì‹œê°„ ì‹¤ì¢…ì íƒì§€ ì‹œìŠ¤í…œ
Korea National Police Agency - Real-Time Missing Person Detection System
"""

import streamlit as st
import cv2
import numpy as np
from PIL import Image
import tempfile
import os
import time
from missing_person_detector_onnx import MissingPersonDetectorONNX


def load_police_css():
    """ê²½ì°°ì²­ ìŠ¤íƒ€ì¼ CSS"""
    st.markdown("""
    <style>
    /* Google Fonts */
    @import url('https://fonts.googleapis.com/css2?family=Inter:wght@300;400;500;600;700;800;900&family=Noto+Sans+KR:wght@300;400;500;700;900&display=swap');

    /* Variables */
    :root {
        --primary: #1D70D5;
        --primary-dark: #1557A8;
        --police-blue: #003DA5;
        --accent: #60A5FA;
        --danger: #EF4444;
        --success: #10B981;
        --warning: #F59E0B;
        --bg-dark: #0A0E1A;
        --text-primary: #F9FAFB;
        --text-secondary: #9CA3AF;
        --border: rgba(59, 130, 246, 0.2);
    }

    /* Global */
    * {
        font-family: 'Noto Sans KR', 'Inter', sans-serif;
    }

    .stApp {
        background: radial-gradient(ellipse at top, #0f172a 0%, #000000 50%, #0a0e1a 100%);
        color: var(--text-primary);
    }

    /* Headers */
    h1 {
        background: linear-gradient(135deg, #3B82F6 0%, #1D70D5 50%, #60A5FA 100%);
        -webkit-background-clip: text;
        -webkit-text-fill-color: transparent;
        background-clip: text;
        font-size: 2.8rem !important;
        font-weight: 900 !important;
        letter-spacing: -0.02em;
        margin-bottom: 0.5rem !important;
    }

    h2 {
        color: var(--accent);
        font-size: 1.6rem !important;
        font-weight: 700 !important;
    }

    h3 {
        color: var(--primary);
        font-size: 1.2rem !important;
        font-weight: 600 !important;
    }

    /* Sidebar */
    [data-testid="stSidebar"] {
        background: linear-gradient(180deg, rgba(15, 23, 42, 0.98), rgba(10, 14, 26, 0.98));
        backdrop-filter: blur(20px);
        border-right: 1px solid var(--border);
    }

    /* Buttons */
    .stButton > button {
        background: linear-gradient(135deg, var(--primary), var(--primary-dark)) !important;
        color: white !important;
        border: none !important;
        border-radius: 12px !important;
        padding: 1rem 2rem !important;
        font-weight: 700 !important;
        font-size: 1.1rem !important;
        text-transform: uppercase !important;
        letter-spacing: 0.05em !important;
        box-shadow: 0 10px 25px -5px rgba(29, 112, 213, 0.5) !important;
        transition: all 0.3s ease !important;
        width: 100%;
    }

    .stButton > button:hover {
        background: linear-gradient(135deg, var(--primary-dark), var(--police-blue)) !important;
        transform: translateY(-3px) !important;
        box-shadow: 0 15px 35px -5px rgba(29, 112, 213, 0.7) !important;
    }

    /* Download Button */
    .stDownloadButton > button {
        background: linear-gradient(135deg, var(--success), #059669) !important;
        box-shadow: 0 10px 25px -5px rgba(16, 185, 129, 0.5) !important;
    }

    .stDownloadButton > button:hover {
        background: linear-gradient(135deg, #059669, #047857) !important;
        transform: translateY(-3px) !important;
    }

    /* File Uploader */
    [data-testid="stFileUploader"] {
        background: rgba(15, 23, 42, 0.6) !important;
        border: 2px dashed var(--border) !important;
        border-radius: 16px !important;
        padding: 2rem !important;
        backdrop-filter: blur(20px) !important;
        transition: all 0.3s ease !important;
    }

    [data-testid="stFileUploader"]:hover {
        border-color: var(--primary) !important;
        background: rgba(29, 112, 213, 0.08) !important;
    }

    [data-testid="stFileUploader"] label {
        color: var(--primary) !important;
        font-weight: 600 !important;
        font-size: 1rem !important;
    }

    /* Inputs */
    input, select, textarea {
        background: rgba(15, 23, 42, 0.6) !important;
        border: 1px solid var(--border) !important;
        border-radius: 10px !important;
        color: var(--text-primary) !important;
        padding: 0.75rem !important;
        font-weight: 500 !important;
    }

    input:focus, select:focus {
        border-color: var(--primary) !important;
        box-shadow: 0 0 0 3px rgba(29, 112, 213, 0.2) !important;
    }

    /* Sliders */
    [data-testid="stSlider"] {
        background: rgba(29, 112, 213, 0.08) !important;
        border: 1px solid rgba(29, 112, 213, 0.25) !important;
        border-radius: 12px !important;
        padding: 1.5rem !important;
    }

    [data-testid="stSlider"] label {
        color: var(--primary) !important;
        font-weight: 600 !important;
    }

    /* Radio */
    [data-testid="stRadio"] {
        background: rgba(29, 112, 213, 0.05) !important;
        border: 1px solid rgba(29, 112, 213, 0.2) !important;
        border-radius: 10px !important;
        padding: 1rem !important;
    }

    /* Checkbox */
    [data-testid="stCheckbox"] label {
        color: var(--text-primary) !important;
        font-weight: 500 !important;
    }

    /* Metrics */
    [data-testid="stMetricValue"] {
        color: var(--primary) !important;
        font-size: 2.5rem !important;
        font-weight: 800 !important;
    }

    [data-testid="stMetricLabel"] {
        color: var(--text-secondary) !important;
        font-weight: 600 !important;
        text-transform: uppercase !important;
        letter-spacing: 0.05em !important;
    }

    /* Alerts */
    .stSuccess {
        background: rgba(16, 185, 129, 0.12) !important;
        border: 1px solid rgba(16, 185, 129, 0.4) !important;
        border-radius: 12px !important;
        font-weight: 600 !important;
    }

    .stWarning {
        background: rgba(245, 158, 11, 0.12) !important;
        border: 1px solid rgba(245, 158, 11, 0.4) !important;
        border-radius: 12px !important;
        font-weight: 600 !important;
    }

    .stError {
        background: rgba(239, 68, 68, 0.12) !important;
        border: 1px solid rgba(239, 68, 68, 0.4) !important;
        border-radius: 12px !important;
        font-weight: 600 !important;
    }

    .stInfo {
        background: rgba(29, 112, 213, 0.12) !important;
        border: 1px solid rgba(29, 112, 213, 0.4) !important;
        border-radius: 12px !important;
        font-weight: 600 !important;
    }

    /* Progress */
    .stProgress > div {
        background: rgba(29, 112, 213, 0.15) !important;
        border-radius: 10px !important;
        height: 12px !important;
    }

    .stProgress > div > div {
        background: linear-gradient(90deg, var(--primary), var(--accent)) !important;
    }

    /* Video & Image */
    img, video {
        border-radius: 16px !important;
        box-shadow: 0 20px 50px -10px rgba(0, 0, 0, 0.5) !important;
    }

    /* Expander */
    [data-testid="stExpander"] {
        background: rgba(15, 23, 42, 0.6) !important;
        border: 1px solid var(--border) !important;
        border-radius: 16px !important;
        backdrop-filter: blur(20px) !important;
    }

    /* Code */
    code {
        background: rgba(29, 112, 213, 0.15) !important;
        color: var(--accent) !important;
        padding: 0.3rem 0.6rem !important;
        border-radius: 6px !important;
        font-weight: 600 !important;
    }

    /* Scrollbar */
    ::-webkit-scrollbar {
        width: 12px;
        height: 12px;
    }

    ::-webkit-scrollbar-track {
        background: rgba(10, 14, 26, 0.5);
        border-radius: 10px;
    }

    ::-webkit-scrollbar-thumb {
        background: linear-gradient(180deg, var(--primary), var(--primary-dark));
        border-radius: 10px;
    }

    ::-webkit-scrollbar-thumb:hover {
        background: linear-gradient(180deg, var(--accent), var(--primary));
    }

    /* Hide Streamlit branding */
    #MainMenu {visibility: hidden;}
    footer {visibility: hidden;}
    </style>
    """, unsafe_allow_html=True)


def main():
    st.set_page_config(
        page_title="ê²½ì°°ì²­ ì‹¤ì‹œê°„ ì‹¤ì¢…ì íƒì§€ ì‹œìŠ¤í…œ",
        page_icon="ğŸš¨",
        layout="wide",
        initial_sidebar_state="expanded"
    )

    # ìŠ¤íƒ€ì¼ ë¡œë“œ
    load_police_css()

    # í—¤ë”
    st.title("ğŸš¨ ê²½ì°°ì²­ ì‹¤ì‹œê°„ ì‹¤ì¢…ì íƒì§€ ì‹œìŠ¤í…œ")
    st.caption("KOREA NATIONAL POLICE AGENCY | REAL-TIME MISSING PERSON DETECTION | CCTV SURVEILLANCE SYSTEM")
    st.markdown("---")

    # ì‚¬ì´ë“œë°”
    with st.sidebar:
        st.header("âš™ï¸ ì‹œìŠ¤í…œ ì„¤ì •")

        # ëª¨ë¸ í™•ì¸
        yolo_exists = os.path.exists('yolov8n.onnx')
        osnet_exists = os.path.exists('osnet_x1_0.onnx')

        if not yolo_exists or not osnet_exists:
            st.error("âŒ AI ëª¨ë¸ íŒŒì¼ ì—†ìŒ")
            st.warning("ë‹¤ìŒ ëª…ë ¹ì„ ì‹¤í–‰í•˜ì„¸ìš”:")
            st.code("python convert_to_onnx.py", language="bash")
            st.stop()
        else:
            st.success("âœ… AI ëª¨ë¸ ë¡œë“œ ì™„ë£Œ")

        st.markdown("---")

        # ì‹¤ì¢…ì ì´ë¯¸ì§€
        st.subheader("1ï¸âƒ£ ì‹¤ì¢…ì ì •ë³´")
        uploaded_images = st.file_uploader(
            "ì‹¤ì¢…ì ì‚¬ì§„ ì—…ë¡œë“œ (ì—¬ëŸ¬ ì¥ ê¶Œì¥)",
            type=['jpg', 'jpeg', 'png'],
            accept_multiple_files=True,
            help="ë‹¤ì–‘í•œ ê°ë„ì˜ ì‚¬ì§„ì„ ì—…ë¡œë“œí•˜ë©´ íƒì§€ ì •í™•ë„ê°€ í–¥ìƒë©ë‹ˆë‹¤"
        )

        if uploaded_images:
            st.write(f"ğŸ“¸ ë“±ë¡ëœ ì‚¬ì§„: **{len(uploaded_images)}ì¥**")
            cols = st.columns(min(len(uploaded_images), 3))
            for idx, uploaded_image in enumerate(uploaded_images):
                with cols[idx % 3]:
                    image = Image.open(uploaded_image).convert('RGB')
                    st.image(image, caption=f"ì‚¬ì§„ {idx+1}", use_container_width=True)

        st.markdown("---")

        # ì…ë ¥ ì†ŒìŠ¤
        st.subheader("2ï¸âƒ£ ì˜ìƒ ì†ŒìŠ¤")
        input_source = st.radio(
            "ì…ë ¥ íƒ€ì… ì„ íƒ",
            ["ğŸ“ CCTV ì˜ìƒ íŒŒì¼", "ğŸ“· ì‹¤ì‹œê°„ ì¹´ë©”ë¼"],
            help="ë…¹í™”ëœ CCTV ì˜ìƒ ë˜ëŠ” ì‹¤ì‹œê°„ ì¹´ë©”ë¼ ì„ íƒ"
        )

        uploaded_video = None
        camera_index = 0

        if input_source == "ğŸ“ CCTV ì˜ìƒ íŒŒì¼":
            uploaded_video = st.file_uploader(
                "CCTV ì˜ìƒ ì—…ë¡œë“œ",
                type=['mp4', 'avi', 'mov'],
                help="ë¶„ì„í•  CCTV ì˜ìƒ íŒŒì¼"
            )
        else:
            camera_type = st.radio(
                "ì¹´ë©”ë¼ íƒ€ì…",
                ["ğŸ’» PC ì›¹ìº ", "ğŸ“± íœ´ëŒ€í° ì¹´ë©”ë¼ (IP Webcam)"],
                help="ì—°ê²°ëœ ì¹´ë©”ë¼ ì„ íƒ"
            )

            if camera_type == "ğŸ’» PC ì›¹ìº ":
                camera_index = st.selectbox(
                    "ì¹´ë©”ë¼ ë²ˆí˜¸",
                    options=[0, 1, 2],
                    help="0 = ê¸°ë³¸ ì¹´ë©”ë¼"
                )
            else:
                st.info("""
                **ğŸ“± íœ´ëŒ€í° ì¹´ë©”ë¼ ì—°ê²°:**
                1. IP Webcam ì•± ì„¤ì¹˜
                2. "ì„œë²„ ì‹œì‘" ë²„íŠ¼ í´ë¦­
                3. í‘œì‹œëœ IP ì£¼ì†Œ ì…ë ¥
                """)

                ip_input = st.text_input(
                    "IP Webcam ì£¼ì†Œ",
                    value="192.168.0.106:8080",
                    help="ì˜ˆ: 192.168.0.106:8080"
                )

                if ip_input:
                    if not ip_input.startswith('http'):
                        ip_input = 'http://' + ip_input
                    if not ip_input.endswith('/video'):
                        ip_input = ip_input + '/video'
                    camera_index = ip_input
                    st.success(f"âœ… ì—°ê²° ì£¼ì†Œ: `{camera_index}`")

        st.markdown("---")

        # íƒì§€ ì„¤ì •
        st.subheader("3ï¸âƒ£ íƒì§€ ì„¤ì •")

        use_gpu = st.checkbox(
            "ğŸš€ GPU ê°€ì†",
            value=True,
            help="GPU ì‚¬ìš© ì‹œ ì²˜ë¦¬ ì†ë„ 3-5ë°° í–¥ìƒ"
        )

        matching_strategy = st.selectbox(
            "ë§¤ì¹­ ì•Œê³ ë¦¬ì¦˜",
            options=['average', 'weighted', 'strict', 'max'],
            index=0,
            help="ì—¬ëŸ¬ ì°¸ì¡° ì‚¬ì§„ ë¹„êµ ë°©ì‹"
        )

        strategy_desc = {
            'average': 'ğŸ“Š í‰ê·  ìœ ì‚¬ë„ (ê¶Œì¥)',
            'weighted': 'âš–ï¸ ê°€ì¤‘ í‰ê· ',
            'strict': 'ğŸ¯ ì—„ê²© ëª¨ë“œ (ì •ë°€)',
            'max': 'ğŸ” ìµœëŒ€ê°’ ëª¨ë“œ (ë¯¼ê°)'
        }
        st.caption(strategy_desc[matching_strategy])

        similarity_threshold = st.slider(
            "ìœ ì‚¬ë„ ì„ê³„ê°’",
            min_value=0.5,
            max_value=0.95,
            value=0.75,
            step=0.05,
            help="ë†’ì„ìˆ˜ë¡ ì—„ê²©í•œ íƒì§€ (0.75 ê¶Œì¥)"
        )

        st.markdown("---")

        # ì„±ëŠ¥ ìµœì í™”
        st.subheader("4ï¸âƒ£ ì„±ëŠ¥ ìµœì í™”")

        frame_skip = st.slider(
            "í”„ë ˆì„ ìŠ¤í‚µ",
            min_value=0,
            max_value=5,
            value=0,
            step=1,
            help="0=ì „ì²´ í”„ë ˆì„ ë¶„ì„, 1=1í”„ë ˆì„ ê±´ë„ˆë›°ê¸°"
        )

        if frame_skip > 0:
            st.caption(f"âš¡ ì²˜ë¦¬ ì†ë„ ì•½ **{frame_skip + 1}ë°°** í–¥ìƒ")
        else:
            st.caption("âœ“ ìµœê³  ì •í™•ë„ ëª¨ë“œ")

        resize_factor = st.slider(
            "í•´ìƒë„ ì¡°ì •",
            min_value=0.25,
            max_value=1.0,
            value=1.0,
            step=0.05,
            help="1.0=ì›ë³¸, 0.5=50% ì¶•ì†Œ"
        )

        if resize_factor < 1.0:
            st.caption(f"âš¡ ì²˜ë¦¬ ì†ë„ ì•½ **{(1/resize_factor)**2:.1f}ë°°** í–¥ìƒ")
        else:
            st.caption("âœ“ ì›ë³¸ í•´ìƒë„ ìœ ì§€")

        total_speedup = 3.0
        if frame_skip > 0:
            total_speedup *= (frame_skip + 1)
        if resize_factor < 1.0:
            total_speedup *= (1 / resize_factor) ** 1.5

        st.info(f"ğŸš€ **ì´ ì„±ëŠ¥**: ê¸°ë³¸ ëŒ€ë¹„ ì•½ **{total_speedup:.1f}ë°°** ë¹ ë¦„")

    # ë©”ì¸ ì˜ì—­
    if input_source == "ğŸ“ CCTV ì˜ìƒ íŒŒì¼":
        col1, col2 = st.columns([1, 1])

        with col1:
            st.subheader("ğŸ“Š ì‹œìŠ¤í…œ ìƒíƒœ")

            if uploaded_images and uploaded_video:
                st.success(f"âœ… ë¶„ì„ ì¤€ë¹„ ì™„ë£Œ (ë“±ë¡ ì‚¬ì§„: {len(uploaded_images)}ì¥)")

                with tempfile.NamedTemporaryFile(delete=False, suffix='.mp4') as tmp_video:
                    tmp_video.write(uploaded_video.read())
                    tmp_video_path = tmp_video.name

                cap = cv2.VideoCapture(tmp_video_path)
                width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
                height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
                fps = int(cap.get(cv2.CAP_PROP_FPS))
                total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
                cap.release()

                opt_width = int(width * resize_factor)
                opt_height = int(height * resize_factor)
                opt_frames = total_frames // (frame_skip + 1) if frame_skip > 0 else total_frames

                st.info(f"""
                **CCTV ì˜ìƒ ì •ë³´:**
                - í•´ìƒë„: {width}x{height} â†’ {opt_width}x{opt_height}
                - FPS: {fps}
                - ì´ í”„ë ˆì„: {total_frames:,} â†’ {opt_frames:,}
                - ì˜ˆìƒ ì†Œìš” ì‹œê°„: ì•½ {opt_frames / (total_speedup * 10):.0f}ì´ˆ
                """)

            elif not uploaded_images:
                st.warning("âš ï¸ ì‹¤ì¢…ì ì‚¬ì§„ì„ ì—…ë¡œë“œí•´ì£¼ì„¸ìš”")
            elif not uploaded_video:
                st.warning("âš ï¸ CCTV ì˜ìƒì„ ì—…ë¡œë“œí•´ì£¼ì„¸ìš”")

        with col2:
            st.subheader("ğŸš€ íƒì§€ ì‹œì‘")

            if st.button("ğŸ” ì‹¤ì¢…ì íƒì§€ ì‹œì‘", type="primary", use_container_width=True):
                if not uploaded_images or not uploaded_video:
                    st.error("âŒ ì‹¤ì¢…ì ì‚¬ì§„ê³¼ CCTV ì˜ìƒì„ ëª¨ë‘ ì—…ë¡œë“œí•´ì£¼ì„¸ìš”")
                else:
                    try:
                        with tempfile.NamedTemporaryFile(delete=False, suffix='.mp4') as tmp_video:
                            uploaded_video.seek(0)
                            tmp_video.write(uploaded_video.read())
                            tmp_video_path = tmp_video.name

                        output_path = tempfile.mktemp(suffix='.mp4')

                        with st.spinner("ğŸ”„ AI ëª¨ë¸ ë¡œë”© ì¤‘..."):
                            detector = MissingPersonDetectorONNX(
                                yolo_onnx_path='yolov8n.onnx',
                                osnet_onnx_path='osnet_x1_0.onnx',
                                similarity_threshold=similarity_threshold,
                                matching_strategy=matching_strategy,
                                frame_skip=frame_skip,
                                resize_factor=resize_factor,
                                use_gpu=use_gpu
                            )

                        images = []
                        for uploaded_img in uploaded_images:
                            uploaded_img.seek(0)
                            image = Image.open(uploaded_img).convert('RGB')
                            images.append(image)

                        if len(images) == 1:
                            detector.set_missing_person(images[0])
                        else:
                            detector.set_missing_persons(images)

                        progress_bar = st.progress(0)
                        status_text = st.empty()

                        def progress_callback(progress, frame_count, total_frames, fps_current, detection_count):
                            progress_bar.progress(progress)
                            status_text.text(
                                f"âš¡ ë¶„ì„ ì¤‘... {frame_count}/{total_frames} í”„ë ˆì„ | "
                                f"{fps_current:.1f} fps | íƒì§€: {detection_count}íšŒ"
                            )

                        start_time = time.time()
                        with st.spinner("ğŸš€ CCTV ì˜ìƒ ë¶„ì„ ì¤‘..."):
                            results = detector.process_video(
                                tmp_video_path,
                                output_path,
                                progress_callback=progress_callback
                            )

                        processing_time = time.time() - start_time

                        st.success("âœ… ë¶„ì„ ì™„ë£Œ!")

                        col_r1, col_r2, col_r3, col_r4 = st.columns(4)
                        with col_r1:
                            st.metric("ì´ í”„ë ˆì„", f"{results['total_frames']:,}")
                        with col_r2:
                            st.metric("ì²˜ë¦¬ í”„ë ˆì„", f"{results['processed_frames']:,}")
                        with col_r3:
                            st.metric("íƒì§€ íšŸìˆ˜", f"{results['detection_count']:,}")
                        with col_r4:
                            st.metric("í‰ê·  FPS", f"{results['avg_fps']:.1f}")

                        st.info(f"â±ï¸ ì²˜ë¦¬ ì‹œê°„: {processing_time:.1f}ì´ˆ")

                        st.markdown("---")
                        st.subheader("ğŸ“¹ ë¶„ì„ ê²°ê³¼ ì˜ìƒ")

                        if os.path.exists(output_path):
                            with open(output_path, 'rb') as f:
                                video_bytes = f.read()

                            st.video(video_bytes)

                            st.download_button(
                                label="â¬‡ï¸ ê²°ê³¼ ì˜ìƒ ë‹¤ìš´ë¡œë“œ",
                                data=video_bytes,
                                file_name=f"detection_result_{int(time.time())}.mp4",
                                mime="video/mp4",
                                use_container_width=True
                            )

                            os.unlink(output_path)

                        os.unlink(tmp_video_path)

                    except Exception as e:
                        st.error(f"âŒ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
                        import traceback
                        st.code(traceback.format_exc())

    # ì‹¤ì‹œê°„ ì¹´ë©”ë¼ ëª¨ë“œ
    else:
        st.subheader("ğŸ“¹ ì‹¤ì‹œê°„ íƒì§€ í™”ë©´")

        if not uploaded_images:
            st.warning("âš ï¸ ì‹¤ì¢…ì ì‚¬ì§„ì„ ë¨¼ì € ì—…ë¡œë“œí•´ì£¼ì„¸ìš”")
        else:
            camera_display = camera_index if isinstance(camera_index, str) else f"ì¹´ë©”ë¼ {camera_index}"
            st.info(f"ğŸ“· **ì¹´ë©”ë¼**: {camera_display} | **ì„ê³„ê°’**: {similarity_threshold:.2f}")

            col_btn1, col_btn2 = st.columns([1, 1])

            with col_btn1:
                start_btn = st.button("â–¶ï¸ ì‹¤ì‹œê°„ íƒì§€ ì‹œì‘", type="primary", use_container_width=True)

            with col_btn2:
                if 'webcam_running' in st.session_state and st.session_state.webcam_running:
                    if st.button("â¹ï¸ ì¤‘ì§€", type="secondary", use_container_width=True):
                        st.session_state.webcam_running = False
                        st.rerun()

            if start_btn:
                try:
                    with st.spinner("ğŸ”„ AI ëª¨ë¸ ì´ˆê¸°í™” ì¤‘..."):
                        detector = MissingPersonDetectorONNX(
                            yolo_onnx_path='yolov8n.onnx',
                            osnet_onnx_path='osnet_x1_0.onnx',
                            similarity_threshold=similarity_threshold,
                            matching_strategy=matching_strategy,
                            frame_skip=frame_skip,
                            resize_factor=resize_factor,
                            use_gpu=use_gpu
                        )

                    images = []
                    for uploaded_img in uploaded_images:
                        uploaded_img.seek(0)
                        image = Image.open(uploaded_img).convert('RGB')
                        images.append(image)

                    if len(images) == 1:
                        detector.set_missing_person(images[0])
                    else:
                        detector.set_missing_persons(images)

                    cap = cv2.VideoCapture(camera_index)

                    if not cap.isOpened():
                        st.error(f"âŒ ì¹´ë©”ë¼ë¥¼ ì—´ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {camera_index}")
                    else:
                        width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
                        height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))

                        if resize_factor != 1.0:
                            width = int(width * resize_factor)
                            height = int(height * resize_factor)

                        st.success("âœ… ì‹¤ì‹œê°„ ëª¨ë‹ˆí„°ë§ ì‹œì‘")
                        st.markdown("---")

                        # ì˜ìƒ í‘œì‹œ ì˜ì—­
                        frame_placeholder = st.empty()

                        # ìƒíƒœ í‘œì‹œ
                        col_m1, col_m2, col_m3, col_m4 = st.columns(4)
                        metric_placeholders = {
                            'frames': col_m1.empty(),
                            'detections': col_m2.empty(),
                            'fps': col_m3.empty(),
                            'status': col_m4.empty()
                        }

                        frame_count = 0
                        processed_count = 0
                        detection_count = 0
                        start_time = time.time()

                        st.session_state.webcam_running = True

                        while st.session_state.get('webcam_running', False):
                            ret, frame = cap.read()
                            if not ret:
                                st.error("âŒ ì¹´ë©”ë¼ ì—°ê²° ì˜¤ë¥˜")
                                break

                            frame_count += 1
                            elapsed = time.time() - start_time

                            if frame_skip > 0 and (frame_count - 1) % (frame_skip + 1) != 0:
                                continue

                            processed_count += 1

                            if resize_factor != 1.0:
                                frame = cv2.resize(frame, (width, height))

                            detections = detector.detect_persons(frame)

                            for det in detections:
                                x1, y1, x2, y2 = det['bbox']
                                person_img = frame[y1:y2, x1:x2]
                                if person_img.size == 0:
                                    continue

                                try:
                                    person_embedding = detector.extract_embedding(person_img)
                                    similarity = detector.compute_similarity(person_embedding)

                                    if similarity >= similarity_threshold:
                                        detection_count += 1

                                        # ë¹¨ê°„ìƒ‰ ê²½ê³  ë°•ìŠ¤
                                        cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 0, 255), 4)

                                        label = f"ì‹¤ì¢…ì ë°œê²¬! {similarity:.2f}"
                                        label_size, _ = cv2.getTextSize(label, cv2.FONT_HERSHEY_DUPLEX, 1.0, 2)

                                        cv2.rectangle(frame,
                                                    (x1, y1 - label_size[1] - 15),
                                                    (x1 + label_size[0] + 10, y1),
                                                    (0, 0, 255), -1)

                                        cv2.putText(frame, label, (x1 + 5, y1 - 8),
                                                  cv2.FONT_HERSHEY_DUPLEX, 1.0, (255, 255, 255), 2)
                                    else:
                                        cv2.rectangle(frame, (x1, y1), (x2, y2), (128, 128, 128), 2)
                                        cv2.putText(frame, f"{similarity:.2f}", (x1, y1 - 5),
                                                  cv2.FONT_HERSHEY_SIMPLEX, 0.6, (128, 128, 128), 2)

                                except Exception:
                                    continue

                            fps_current = processed_count / elapsed if elapsed > 0 else 0

                            # ìƒíƒœ í‘œì‹œ
                            status = "ğŸŸ¢ ê°ì‹œ ì¤‘" if detection_count == 0 else f"ğŸ”´ ê²½ê³  ({detection_count}ê±´)"
                            status_color = (0, 255, 0) if detection_count == 0 else (0, 0, 255)

                            cv2.putText(frame, status, (10, 40),
                                       cv2.FONT_HERSHEY_DUPLEX, 1.2, status_color, 3)

                            cv2.putText(frame, f"FPS: {fps_current:.1f}", (10, height - 20),
                                       cv2.FONT_HERSHEY_SIMPLEX, 0.8, (255, 255, 255), 2)

                            # ë¸Œë¼ìš°ì €ì— í‘œì‹œ
                            frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
                            frame_placeholder.image(frame_rgb, channels="RGB", use_container_width=True)

                            # ë©”íŠ¸ë¦­ ì—…ë°ì´íŠ¸
                            metric_placeholders['frames'].metric("ì²˜ë¦¬ í”„ë ˆì„", f"{processed_count:,}")
                            metric_placeholders['detections'].metric("íƒì§€ íšŸìˆ˜", f"{detection_count}")
                            metric_placeholders['fps'].metric("FPS", f"{fps_current:.1f}")
                            metric_placeholders['status'].metric("ìƒíƒœ", "ğŸ”´ ê²½ê³ " if detection_count > 0 else "ğŸŸ¢ ì •ìƒ")

                        cap.release()
                        st.session_state.webcam_running = False

                        elapsed_time = time.time() - start_time
                        st.success(f"âœ… ëª¨ë‹ˆí„°ë§ ì¢…ë£Œ | ì‹¤í–‰ ì‹œê°„: {elapsed_time:.1f}ì´ˆ | í‰ê·  FPS: {processed_count/elapsed_time:.1f}")

                        if detection_count > 0:
                            st.warning(f"âš ï¸ **ê²½ê³ **: ì‹¤ì¢…ìê°€ ì´ **{detection_count}íšŒ** íƒì§€ë˜ì—ˆìŠµë‹ˆë‹¤!")

                except Exception as e:
                    st.error(f"âŒ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
                    import traceback
                    st.code(traceback.format_exc())
                    st.session_state.webcam_running = False

    # í•˜ë‹¨ ì •ë³´
    st.markdown("---")
    with st.expander("ğŸ“– ì‚¬ìš© ê°€ì´ë“œ"):
        st.markdown("""
        ## ğŸš€ ë¹ ë¥¸ ì‹œì‘

        1. ì‹¤ì¢…ì ì‚¬ì§„ ì—…ë¡œë“œ (ì¢Œì¸¡ ì‚¬ì´ë“œë°”)
        2. CCTV ì˜ìƒ ë˜ëŠ” ì‹¤ì‹œê°„ ì¹´ë©”ë¼ ì„ íƒ
        3. íƒì§€ ì„¤ì • ë° ì„±ëŠ¥ ì˜µì…˜ ì¡°ì •
        4. **íƒì§€ ì‹œì‘** ë²„íŠ¼ í´ë¦­

        ## âš™ï¸ ê¶Œì¥ ì„¤ì •

        | í™˜ê²½ | í”„ë ˆì„ ìŠ¤í‚µ | í•´ìƒë„ | ìš©ë„ |
        |------|-------------|--------|------|
        | ê³ ì„±ëŠ¥ PC | 0 | 100% | ì •ë°€ ë¶„ì„ |
        | ì¼ë°˜ PC | 1 | 75% | ì¼ë°˜ ê°ì‹œ |
        | ì €ì‚¬ì–‘ PC | 2 | 50% | ë¹ ë¥¸ ìŠ¤ìº” |

        ## ğŸ’¡ íŒ

        - **ì—¬ëŸ¬ ì¥ ë“±ë¡**: 3-5ì¥ì˜ ë‹¤ì–‘í•œ ê°ë„ ì‚¬ì§„ ê¶Œì¥
        - **GPU ì‚¬ìš©**: 3-5ë°° ë¹ ë¥¸ ì²˜ë¦¬
        - **íœ´ëŒ€í° ì¹´ë©”ë¼**: IP Webcam ì•±ìœ¼ë¡œ ì—°ê²° ê°€ëŠ¥
        """)

    with st.expander("ğŸ”§ ê¸°ìˆ  ì‚¬ì–‘"):
        st.markdown("""
        ### AI ì—”ì§„

        - **YOLOv8**: ì‹¤ì‹œê°„ ì‚¬ëŒ íƒì§€
        - **OSNet**: ì¸ë¬¼ ì¬ì‹ë³„ (Re-ID)
        - **ONNX Runtime**: í•˜ë“œì›¨ì–´ ê°€ì† ì¶”ë¡ 

        ### ì„±ëŠ¥

        - ê¸°ë³¸ ì†ë„: ì¼ë°˜ ëŒ€ë¹„ 3ë°° ë¹ ë¦„
        - GPU ê°€ì†: ìµœëŒ€ 5ë°° í–¥ìƒ
        - ìµœì í™” ì ìš©: ìµœëŒ€ 30ë°° í–¥ìƒ

        ### ì‹œìŠ¤í…œ ìš”êµ¬ì‚¬í•­

        - CPU: ìµœì‹  í”„ë¡œì„¸ì„œ
        - GPU: NVIDIA CUDA 11.0+ (ê¶Œì¥)
        - RAM: 8GB ì´ìƒ
        - VRAM: 2GB ì´ìƒ (GPU ì‚¬ìš© ì‹œ)
        """)


if __name__ == "__main__":
    main()
